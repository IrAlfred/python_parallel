# Chapitre 3 : Concepts fondamentaux

## Objectifs d'apprentissage
√Ä la fin de ce chapitre, vous serez capable de :
- Distinguer la concurrence du parall√©lisme
- Comprendre la diff√©rence entre threads et processus
- Ma√Ætriser les concepts de synchronisation et de verrous
- Identifier et r√©soudre les conditions de course (race conditions)
- Comprendre et √©viter les deadlocks et livelocks
- Comprendre les diff√©rences entre m√©moire partag√©e et m√©moire distribu√©e

---

## 1. Explication du principe

### 1.1 Concurrence vs Parall√©lisme

**Concurrence (Concurrency) :**
La concurrence signifie que plusieurs t√¢ches peuvent √™tre en cours d'ex√©cution en m√™me temps, mais pas n√©cessairement simultan√©ment. C'est comme un serveur de restaurant qui g√®re plusieurs tables : il passe d'une table √† l'autre, donnant l'impression qu'il s'occupe de toutes en m√™me temps, mais il ne peut √™tre qu'√† une seule table √† la fois.

**Parall√©lisme (Parallelism) :**
Le parall√©lisme signifie que plusieurs t√¢ches s'ex√©cutent vraiment en m√™me temps, sur plusieurs c≈ìurs de processeur. C'est comme avoir plusieurs serveurs dans le restaurant, chacun s'occupant de tables diff√©rentes simultan√©ment.

**Diff√©rences cl√©s :**

| Aspect | Concurrence | Parall√©lisme |
|--------|-------------|--------------|
| **Ex√©cution** | Apparente simultan√©it√© | Vraie simultan√©it√© |
| **C≈ìurs** | Peut fonctionner sur 1 c≈ìur | N√©cessite plusieurs c≈ìurs |
| **Utilisation** | I/O, interface utilisateur | Calculs CPU intensifs |
| **Exemple Python** | `threading`, `asyncio` | `multiprocessing` |

**Points cl√©s √† retenir :**
- La **concurrence** g√®re plusieurs t√¢ches en alternance (time-slicing)
- Le **parall√©lisme** ex√©cute plusieurs t√¢ches vraiment en m√™me temps
- En Python, √† cause du GIL, le threading est plut√¥t de la concurrence que du parall√©lisme
- Le multiprocessing permet le vrai parall√©lisme

### 1.2 Threads vs Processus

**Threads :**
Un thread (fil d'ex√©cution) est une unit√© d'ex√©cution plus l√©g√®re qu'un processus. Plusieurs threads partagent la m√™me m√©moire et les m√™mes ressources du processus parent.

**Caract√©ristiques des threads :**
- Partage de la m√©moire (variables globales accessibles par tous)
- Cr√©ation rapide (moins de ressources)
- Communication facile (m√©moire partag√©e)
- Moins isol√©s (une erreur peut affecter les autres threads)

**Processus :**
Un processus est une instance d'un programme en cours d'ex√©cution. Chaque processus a sa propre m√©moire isol√©e.

**Caract√©ristiques des processus :**
- M√©moire isol√©e (pas de partage direct)
- Cr√©ation plus lourde (plus de ressources)
- Communication plus complexe (pipes, queues, m√©moire partag√©e explicite)
- Tr√®s isol√©s (une erreur n'affecte pas les autres processus)

**Comparaison :**

| Aspect | Threads | Processus |
|--------|---------|------------|
| **M√©moire** | Partag√©e | Isol√©e |
| **Cr√©ation** | Rapide (~1ms) | Plus lente (~10-100ms) |
| **Communication** | Directe (m√©moire) | Via IPC (Inter-Process Communication) |
| **Isolation** | Faible | Forte |
| **GIL** | Affect√© | Non affect√© (chaque processus a son GIL) |

**Quand utiliser quoi ?**
- **Threads** : Op√©rations I/O (fichiers, r√©seau), interface utilisateur
- **Processus** : Calculs CPU intensifs, quand on veut vraiment utiliser plusieurs c≈ìurs

**Points cl√©s √† retenir :**
- Les threads sont plus l√©gers mais partagent la m√©moire
- Les processus sont plus lourds mais sont isol√©s
- En Python, pour le calcul CPU, utilisez des processus √† cause du GIL

### 1.3 Synchronisation et verrous

**Pourquoi la synchronisation ?**
Quand plusieurs threads/processus acc√®dent √† la m√™me ressource (variable, fichier, etc.), il faut coordonner leurs acc√®s pour √©viter les conflits.

**Verrous (Locks) :**
Un verrou est un m√©canisme qui permet √† un seul thread/processus d'acc√©der √† une ressource √† la fois. C'est comme une cl√© de salle de bain : une seule personne peut l'utiliser √† la fois.

**Comment fonctionne un verrou :**
1. Un thread demande le verrou (`acquire()`)
2. Si disponible, il l'obtient et acc√®de √† la ressource
3. Si occup√©, il attend que le verrou soit lib√©r√©
4. Apr√®s utilisation, il lib√®re le verrou (`release()`)

**Types de verrous :**
- **Lock simple** : Un thread √† la fois
- **RLock (Reentrant Lock)** : Permet au m√™me thread de verrouiller plusieurs fois
- **Semaphore** : Permet √† N threads d'acc√©der simultan√©ment

**Points cl√©s √† retenir :**
- Les verrous prot√®gent les ressources partag√©es
- Un verrou mal utilis√© peut causer des deadlocks
- Il faut toujours lib√©rer un verrou apr√®s utilisation

### 1.4 Conditions de course (Race Conditions)

**Qu'est-ce qu'une race condition ?**
Une race condition se produit quand le r√©sultat d'un programme d√©pend de l'ordre d'ex√©cution des threads/processus, qui est non d√©terministe. C'est comme deux personnes qui essaient de modifier le m√™me document en m√™me temps sans coordination.

**Exemple classique :**
```python
# Variable partag√©e
compteur = 0

# Thread 1
compteur = compteur + 1  # Lit 0, calcule 1, √©crit 1

# Thread 2 (en m√™me temps)
compteur = compteur + 1  # Lit 0 (avant que Thread 1 n'√©crive), calcule 1, √©crit 1

# R√©sultat attendu : 2
# R√©sultat obtenu : 1 (ou parfois 2, selon le timing)
```

**Pourquoi c'est dangereux ?**
- Les r√©sultats sont impr√©visibles
- Les bugs sont difficiles √† reproduire
- Les erreurs peuvent √™tre subtiles et passer inaper√ßues

**Comment √©viter les race conditions ?**
- Utiliser des verrous pour prot√©ger les acc√®s
- Utiliser des structures thread-safe (Queue, etc.)
- √âviter le partage d'√©tat quand possible
- Utiliser des op√©rations atomiques

**Points cl√©s √† retenir :**
- Les race conditions sont caus√©es par des acc√®s non synchronis√©s
- Elles sont difficiles √† d√©tecter et √† d√©boguer
- Toujours prot√©ger les acc√®s aux ressources partag√©es

### 1.5 Deadlocks et livelocks

**Deadlock (Interblocage) :**
Un deadlock se produit quand deux ou plusieurs threads/processus s'attendent mutuellement, cr√©ant une situation o√π aucun ne peut progresser. C'est comme deux personnes qui se tiennent la main et attendent que l'autre l√¢che en premier.

**Exemple de deadlock :**
```python
# Thread 1
verrou1.acquire()  # Obtient verrou1
verrou2.acquire()  # Attend verrou2 (d√©tenu par Thread 2)

# Thread 2
verrou2.acquire()  # Obtient verrou2
verrou1.acquire()  # Attend verrou1 (d√©tenu par Thread 1)

# R√©sultat : Les deux threads sont bloqu√©s ind√©finiment
```

**Conditions n√©cessaires pour un deadlock (Conditions de Coffman) :**
1. **Exclusion mutuelle** : Une ressource ne peut √™tre utilis√©e que par un processus √† la fois
2. **R√©tention et attente** : Un processus d√©tient une ressource et attend une autre
3. **Pas de pr√©emption** : Les ressources ne peuvent pas √™tre retir√©es de force
4. **Attente circulaire** : Il existe un cycle de processus qui s'attendent mutuellement

**Livelock :**
Un livelock est similaire √† un deadlock, mais les processus continuent d'essayer de progresser sans succ√®s. C'est comme deux personnes qui se croisent dans un couloir et continuent de bouger sans jamais se d√©bloquer.

**Comment √©viter les deadlocks :**
1. **Ordre constant des verrous** : Toujours acqu√©rir les verrous dans le m√™me ordre
2. **Timeout sur les verrous** : Ne pas attendre ind√©finiment
3. **D√©tection de deadlock** : Surveiller et d√©tecter les cycles
4. **√âviter les verrous multiples** : Utiliser un seul verrou quand possible

**Points cl√©s √† retenir :**
- Les deadlocks bloquent compl√®tement l'ex√©cution
- Les livelocks font tourner les processus sans progresser
- Pr√©venir est mieux que gu√©rir : concevez votre code pour √©viter ces situations

### 1.6 Partage de m√©moire vs m√©moire distribu√©e

**M√©moire partag√©e (Shared Memory) :**
Dans un syst√®me √† m√©moire partag√©e, tous les threads/processus acc√®dent √† la m√™me m√©moire physique. C'est comme plusieurs personnes qui travaillent sur le m√™me tableau blanc.

**Avantages :**
- Communication rapide (pas de copie de donn√©es)
- Acc√®s direct aux donn√©es
- Simple √† utiliser

**Inconv√©nients :**
- Risque de race conditions
- Besoin de synchronisation
- Difficile √† scaler sur plusieurs machines

**M√©moire distribu√©e (Distributed Memory) :**
Dans un syst√®me √† m√©moire distribu√©e, chaque processus a sa propre m√©moire. La communication se fait via messages. C'est comme plusieurs personnes qui travaillent sur des tableaux s√©par√©s et s'envoient des messages.

**Avantages :**
- Pas de race conditions (m√©moire isol√©e)
- Scalable sur plusieurs machines
- Plus robuste (une erreur n'affecte pas les autres)

**Inconv√©nients :**
- Communication plus lente (s√©rialisation, r√©seau)
- Plus complexe √† programmer
- Overhead de communication

**Points cl√©s √† retenir :**
- **Threads** : M√©moire partag√©e (rapide mais n√©cessite synchronisation)
- **Processus** : M√©moire isol√©e (s√©curis√© mais communication n√©cessaire)
- **Distribu√©** : M√©moire s√©par√©e sur diff√©rentes machines (scalable mais complexe)

---

## 2. Exemples basiques

### 2.1 Exemple basique 1 : Race condition sur un compteur

#### 2.1.1 Description

Nous allons cr√©er un exemple qui illustre une race condition classique : l'incr√©mentation d'un compteur partag√© par plusieurs threads. Cet exemple montrera le probl√®me et comment le r√©soudre avec un verrou.

**Ce que nous allons faire :**
- Cr√©er un compteur partag√©
- Lancer plusieurs threads qui l'incr√©mentent
- Observer le probl√®me de race condition
- R√©soudre le probl√®me avec un verrou

#### 2.1.2 Code

```python
import threading
import time

# Compteur partag√© (sans protection)
compteur_sans_verrou = 0

# Compteur partag√© (avec protection)
compteur_avec_verrou = 0
verrou = threading.Lock()

def incrementer_sans_verrou(nb_iterations):
    """
    Incr√©mente le compteur sans protection (race condition).
    
    Args:
        nb_iterations (int): Nombre de fois √† incr√©menter
    """
    global compteur_sans_verrou
    
    for _ in range(nb_iterations):
        # Op√©ration non atomique : lecture, calcul, √©criture
        valeur_actuelle = compteur_sans_verrou
        time.sleep(0.0001)  # Simule un petit d√©lai
        compteur_sans_verrou = valeur_actuelle + 1

def incrementer_avec_verrou(nb_iterations):
    """
    Incr√©mente le compteur avec protection (pas de race condition).
    
    Args:
        nb_iterations (int): Nombre de fois √† incr√©menter
    """
    global compteur_avec_verrou
    
    for _ in range(nb_iterations):
        # Prot√©ger l'acc√®s avec un verrou
        verrou.acquire()
        try:
            valeur_actuelle = compteur_avec_verrou
            time.sleep(0.0001)  # Simule un petit d√©lai
            compteur_avec_verrou = valeur_actuelle + 1
        finally:
            verrou.release()  # Toujours lib√©rer le verrou

def test_race_condition():
    """Test qui montre la race condition."""
    global compteur_sans_verrou
    
    compteur_sans_verrou = 0
    nb_threads = 5
    nb_iterations_par_thread = 100
    
    print("=== Test sans verrou (Race Condition) ===\n")
    print(f"Lancement de {nb_threads} threads, chacun incr√©mente {nb_iterations_par_thread} fois")
    print(f"Valeur attendue : {nb_threads * nb_iterations_par_thread}\n")
    
    threads = []
    for i in range(nb_threads):
        t = threading.Thread(target=incrementer_sans_verrou, args=(nb_iterations_par_thread,))
        threads.append(t)
        t.start()
    
    # Attendre que tous les threads se terminent
    for t in threads:
        t.join()
    
    print(f"Valeur obtenue : {compteur_sans_verrou}")
    print(f"Diff√©rence : {nb_threads * nb_iterations_par_thread - compteur_sans_verrou}")
    
    if compteur_sans_verrou != nb_threads * nb_iterations_par_thread:
        print("‚ö†Ô∏è  RACE CONDITION D√âTECT√âE ! La valeur est incorrecte.\n")
    else:
        print("‚úì Valeur correcte (par chance, mais ce n'est pas garanti)\n")

def test_avec_verrou():
    """Test avec verrou (pas de race condition)."""
    global compteur_avec_verrou
    
    compteur_avec_verrou = 0
    nb_threads = 5
    nb_iterations_par_thread = 100
    
    print("=== Test avec verrou (Protection) ===\n")
    print(f"Lancement de {nb_threads} threads, chacun incr√©mente {nb_iterations_par_thread} fois")
    print(f"Valeur attendue : {nb_threads * nb_iterations_par_thread}\n")
    
    threads = []
    for i in range(nb_threads):
        t = threading.Thread(target=incrementer_avec_verrou, args=(nb_iterations_par_thread,))
        threads.append(t)
        t.start()
    
    # Attendre que tous les threads se terminent
    for t in threads:
        t.join()
    
    print(f"Valeur obtenue : {compteur_avec_verrou}")
    print(f"Diff√©rence : {nb_threads * nb_iterations_par_thread - compteur_avec_verrou}")
    
    if compteur_avec_verrou == nb_threads * nb_iterations_par_thread:
        print("‚úì Valeur correcte ! Le verrou prot√®ge contre les race conditions.\n")
    else:
        print("‚ö†Ô∏è  Erreur inattendue\n")

if __name__ == "__main__":
    # Test 1 : Sans protection (race condition)
    test_race_condition()
    
    # Test 2 : Avec protection (verrou)
    test_avec_verrou()
    
    print("=== Conclusion ===")
    print("Le verrou garantit que les op√©rations sur le compteur")
    print("sont atomiques et √©vitent les race conditions.")
```

#### 2.1.3 Explication ligne par ligne

**Lignes 1-2 : Importations**
- `threading` : Pour cr√©er des threads et des verrous
- `time` : Pour simuler des d√©lais

**Lignes 4-9 : Variables globales**
- `compteur_sans_verrou` : Compteur non prot√©g√© (va avoir des race conditions)
- `compteur_avec_verrou` : Compteur prot√©g√©
- `verrou` : Verrou pour prot√©ger le compteur

**Lignes 11-22 : Fonction `incrementer_sans_verrou`**
- Lit la valeur actuelle
- Attend un peu (simule un calcul)
- √âcrit la nouvelle valeur
- **Probl√®me** : Entre la lecture et l'√©criture, un autre thread peut modifier la valeur

**Lignes 24-38 : Fonction `incrementer_avec_verrou`**
- Acquiert le verrou avant d'acc√©der au compteur
- Effectue l'incr√©mentation
- Lib√®re le verrou dans un bloc `finally` (garantit la lib√©ration m√™me en cas d'erreur)
- **Solution** : Le verrou garantit qu'un seul thread modifie le compteur √† la fois

**Lignes 40-68 : Fonction `test_race_condition`**
- Cr√©e plusieurs threads qui incr√©mentent le compteur sans protection
- Montre que le r√©sultat est incorrect

**Lignes 70-96 : Fonction `test_avec_verrou`**
- M√™me test mais avec protection
- Montre que le r√©sultat est correct

#### 2.1.4 R√©sultat attendu

```
=== Test sans verrou (Race Condition) ===

Lancement de 5 threads, chacun incr√©mente 100 fois
Valeur attendue : 500

Valeur obtenue : 487
Diff√©rence : 13
‚ö†Ô∏è  RACE CONDITION D√âTECT√âE ! La valeur est incorrecte.

=== Test avec verrou (Protection) ===

Lancement de 5 threads, chacun incr√©mente 100 fois
Valeur attendue : 500

Valeur obtenue : 500
Diff√©rence : 0
‚úì Valeur correcte ! Le verrou prot√®ge contre les race conditions.

=== Conclusion ===
Le verrou garantit que les op√©rations sur le compteur
sont atomiques et √©vitent les race conditions.
```

*Note : La valeur exacte sans verrou variera √† chaque ex√©cution √† cause de la race condition.*

#### 2.1.5 Analyse du r√©sultat

Le r√©sultat montre clairement :
- **Sans verrou** : La valeur est incorrecte (race condition)
- **Avec verrou** : La valeur est toujours correcte (protection)

Cela illustre l'importance de la synchronisation pour prot√©ger les ressources partag√©es.

---

### 2.2 Exemple basique 2 : Partage de liste sans protection

#### 2.2.1 Description

Cet exemple montre une race condition sur une liste partag√©e. Plusieurs threads ajoutent des √©l√©ments √† une liste sans synchronisation.

#### 2.2.2 Code

```python
import threading

liste_sans_verrou = []
liste_avec_verrou = []
verrou = threading.Lock()

def ajouter_sans_verrou(nb_elements):
    """Ajoute des √©l√©ments sans protection."""
    global liste_sans_verrou
    for i in range(nb_elements):
        liste_sans_verrou.append(i)

def ajouter_avec_verrou(nb_elements):
    """Ajoute des √©l√©ments avec protection."""
    global liste_avec_verrou
    for i in range(nb_elements):
        with verrou:
            liste_avec_verrou.append(i)

if __name__ == "__main__":
    threads = []
    
    # Test sans verrou
    for _ in range(3):
        t = threading.Thread(target=ajouter_sans_verrou, args=(100,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print(f"Sans verrou: {len(liste_sans_verrou)} √©l√©ments (attendu: 300)")
    
    # Test avec verrou
    threads = []
    for _ in range(3):
        t = threading.Thread(target=ajouter_avec_verrou, args=(100,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print(f"Avec verrou: {len(liste_avec_verrou)} √©l√©ments (attendu: 300)")
```

#### 2.2.3 Explication

M√™me si `list.append()` semble atomique, dans un contexte multi-thread, il peut y avoir des probl√®mes. Le verrou garantit que l'op√©ration est vraiment atomique.

---

### 2.3 Exemple basique 3 : Comprendre la concurrence vs parall√©lisme

#### 2.3.1 Description

Cet exemple illustre la diff√©rence entre concurrence (threading) et parall√©lisme (multiprocessing) en Python.

#### 2.3.2 Code

```python
import threading
import multiprocessing
import time

def calcul_cpu(n):
    """Calcul CPU intensif."""
    resultat = 0
    for i in range(n):
        resultat += i * i
    return resultat

def test_threading():
    """Test avec threading (concurrence)."""
    debut = time.time()
    threads = []
    for _ in range(4):
        t = threading.Thread(target=calcul_cpu, args=(1000000,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    return time.time() - debut

def test_multiprocessing():
    """Test avec multiprocessing (parall√©lisme)."""
    debut = time.time()
    processus = []
    for _ in range(4):
        p = multiprocessing.Process(target=calcul_cpu, args=(1000000,))
        processus.append(p)
        p.start()
    
    for p in processus:
        p.join()
    return time.time() - debut

if __name__ == "__main__":
    print("Threading (concurrence):")
    temps_thread = test_threading()
    print(f"  Temps: {temps_thread:.4f}s\n")
    
    print("Multiprocessing (parall√©lisme):")
    temps_proc = test_multiprocessing()
    print(f"  Temps: {temps_proc:.4f}s\n")
    
    print(f"Multiprocessing est {temps_thread/temps_proc:.2f}x plus rapide")
```

#### 2.3.3 Explication

Pour le calcul CPU, multiprocessing est plus efficace car il utilise vraiment plusieurs c≈ìurs, contrairement √† threading qui est limit√© par le GIL.

---

## 3. Exemple avanc√©

### 3.1 Description

Nous allons cr√©er un exemple qui illustre un deadlock classique : deux threads qui ont besoin de deux verrous diff√©rents mais les acqui√®rent dans un ordre diff√©rent. Nous montrerons comment d√©tecter et r√©soudre ce probl√®me.

**Contexte :**
Imaginez un syst√®me bancaire o√π deux comptes doivent transf√©rer de l'argent l'un √† l'autre. Chaque compte a un verrou. Si les deux transferts se font en m√™me temps et acqui√®rent les verrous dans un ordre diff√©rent, on obtient un deadlock.

**Objectifs :**
- Cr√©er un sc√©nario de deadlock
- D√©tecter le deadlock
- R√©soudre le probl√®me avec un ordre constant des verrous
- Utiliser un timeout pour √©viter les blocages infinis

### 3.2 Code

```python
import threading
import time
import random

# Verrous pour deux comptes bancaires
verrou_compte_a = threading.Lock()
verrou_compte_b = threading.Lock()

# Comptes bancaires
compte_a = 1000
compte_b = 1000

def transfert_vers_b(montant, avec_deadlock=True):
    """
    Transf√®re de l'argent du compte A vers le compte B.
    
    Args:
        montant (float): Montant √† transf√©rer
        avec_deadlock (bool): Si True, cr√©e un deadlock potentiel
    """
    global compte_a, compte_b
    
    if avec_deadlock:
        # MAUVAISE APPROCHE : Ordre diff√©rent selon le thread
        print(f"Thread {threading.current_thread().name}: Acquiert verrou A")
        verrou_compte_a.acquire()
        time.sleep(0.1)  # Simule un d√©lai (augmente la chance de deadlock)
        
        print(f"Thread {threading.current_thread().name}: Acquiert verrou B")
        verrou_compte_b.acquire()
    else:
        # BONNE APPROCHE : Ordre constant (toujours A puis B)
        print(f"Thread {threading.current_thread().name}: Acquiert verrou A")
        verrou_compte_a.acquire()
        time.sleep(0.1)
        
        print(f"Thread {threading.current_thread().name}: Acquiert verrou B")
        verrou_compte_b.acquire()
    
    try:
        # Effectuer le transfert
        if compte_a >= montant:
            compte_a -= montant
            compte_b += montant
            print(f"Thread {threading.current_thread().name}: Transfert de {montant} de A vers B")
        else:
            print(f"Thread {threading.current_thread().name}: Fonds insuffisants")
    finally:
        # Lib√©rer dans l'ordre inverse
        verrou_compte_b.release()
        verrou_compte_a.release()
        print(f"Thread {threading.current_thread().name}: Verrous lib√©r√©s")

def transfert_vers_a(montant, avec_deadlock=True):
    """
    Transf√®re de l'argent du compte B vers le compte A.
    
    Args:
        montant (float): Montant √† transf√©rer
        avec_deadlock (bool): Si True, cr√©e un deadlock potentiel
    """
    global compte_a, compte_b
    
    if avec_deadlock:
        # MAUVAISE APPROCHE : Ordre diff√©rent (B puis A)
        print(f"Thread {threading.current_thread().name}: Acquiert verrou B")
        verrou_compte_b.acquire()
        time.sleep(0.1)  # Simule un d√©lai
        
        print(f"Thread {threading.current_thread().name}: Acquiert verrou A")
        verrou_compte_a.acquire()
    else:
        # BONNE APPROCHE : Ordre constant (toujours A puis B)
        print(f"Thread {threading.current_thread().name}: Acquiert verrou A")
        verrou_compte_a.acquire()
        time.sleep(0.1)
        
        print(f"Thread {threading.current_thread().name}: Acquiert verrou B")
        verrou_compte_b.acquire()
    
    try:
        # Effectuer le transfert
        if compte_b >= montant:
            compte_b -= montant
            compte_a += montant
            print(f"Thread {threading.current_thread().name}: Transfert de {montant} de B vers A")
        else:
            print(f"Thread {threading.current_thread().name}: Fonds insuffisants")
    finally:
        # Lib√©rer dans l'ordre inverse
        verrou_compte_b.release()
        verrou_compte_a.release()
        print(f"Thread {threading.current_thread().name}: Verrous lib√©r√©s")

def test_deadlock():
    """Test qui peut cr√©er un deadlock."""
    global compte_a, compte_b
    
    compte_a = 1000
    compte_b = 1000
    
    print("=== Test avec Deadlock Potentiel ===\n")
    print("Situation :")
    print("- Thread 1 : A -> B (acquiert A puis B)")
    print("- Thread 2 : B -> A (acquiert B puis A)")
    print("Risque : Deadlock si les deux threads s'ex√©cutent en m√™me temps\n")
    
    thread1 = threading.Thread(target=transfert_vers_b, args=(100, True), name="Thread-1")
    thread2 = threading.Thread(target=transfert_vers_a, args=(50, True), name="Thread-2")
    
    thread1.start()
    thread2.start()
    
    # Attendre avec timeout pour d√©tecter le deadlock
    thread1.join(timeout=2)
    thread2.join(timeout=2)
    
    if thread1.is_alive() or thread2.is_alive():
        print("\n‚ö†Ô∏è  DEADLOCK D√âTECT√â ! Les threads sont bloqu√©s.")
        print("Solution : Utiliser un ordre constant pour les verrous.\n")
    else:
        print("\n‚úì Transferts termin√©s (par chance, pas de deadlock cette fois)\n")
    
    print(f"√âtat final - Compte A: {compte_a}, Compte B: {compte_b}")

def test_sans_deadlock():
    """Test sans deadlock (ordre constant des verrous)."""
    global compte_a, compte_b
    
    compte_a = 1000
    compte_b = 1000
    
    print("=== Test sans Deadlock (Ordre Constant) ===\n")
    print("Solution : Toujours acqu√©rir les verrous dans le m√™me ordre (A puis B)\n")
    
    thread1 = threading.Thread(target=transfert_vers_b, args=(100, False), name="Thread-1")
    thread2 = threading.Thread(target=transfert_vers_a, args=(50, False), name="Thread-2")
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    print("\n‚úì Transferts termin√©s sans deadlock\n")
    print(f"√âtat final - Compte A: {compte_a}, Compte B: {compte_b}")

def transfert_avec_timeout(montant, timeout=1):
    """
    Version avec timeout pour √©viter les blocages infinis.
    
    Args:
        montant (float): Montant √† transf√©rer
        timeout (float): Timeout en secondes
    """
    global compte_a, compte_b
    
    # Essayer d'acqu√©rir les verrous avec timeout
    if not verrou_compte_a.acquire(timeout=timeout):
        print(f"Thread {threading.current_thread().name}: Timeout sur verrou A")
        return False
    
    try:
        if not verrou_compte_b.acquire(timeout=timeout):
            print(f"Thread {threading.current_thread().name}: Timeout sur verrou B")
            return False
        
        try:
            # Effectuer le transfert
            if compte_a >= montant:
                compte_a -= montant
                compte_b += montant
                print(f"Thread {threading.current_thread().name}: Transfert r√©ussi")
                return True
            else:
                print(f"Thread {threading.current_thread().name}: Fonds insuffisants")
                return False
        finally:
            verrou_compte_b.release()
    finally:
        verrou_compte_a.release()
    
    return False

if __name__ == "__main__":
    # Test 1 : Avec deadlock potentiel
    test_deadlock()
    
    print("\n" + "="*50 + "\n")
    
    # Test 2 : Sans deadlock (solution)
    test_sans_deadlock()
    
    print("\n" + "="*50 + "\n")
    
    # Test 3 : Avec timeout
    print("=== Test avec Timeout ===\n")
    compte_a = 1000
    compte_b = 1000
    
    thread1 = threading.Thread(target=transfert_avec_timeout, args=(100, 0.5), name="Thread-1")
    thread2 = threading.Thread(target=transfert_avec_timeout, args=(50, 0.5), name="Thread-2")
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    print(f"\n√âtat final - Compte A: {compte_a}, Compte B: {compte_b}")
```

### 3.3 Explication d√©taill√©e

**Architecture :**
L'exemple simule un syst√®me bancaire avec deux comptes. Les transferts n√©cessitent d'acqu√©rir les verrous des deux comptes, cr√©ant un risque de deadlock.

**Fonctionnalit√©s :**

1. **Transferts avec deadlock potentiel** :
   - Thread 1 acquiert A puis B
   - Thread 2 acquiert B puis A
   - Si les deux s'ex√©cutent en m√™me temps ‚Üí deadlock

2. **Transferts sans deadlock** :
   - Toujours acqu√©rir A puis B (ordre constant)
   - M√™me si les transferts vont dans des directions diff√©rentes

3. **Transferts avec timeout** :
   - Utilise `acquire(timeout=...)` pour √©viter les blocages infinis
   - Retourne False si le timeout est atteint

**Points techniques importants :**

- **Ordre constant des verrous** : Toujours acqu√©rir les verrous dans le m√™me ordre (par exemple, toujours par ordre alphab√©tique ou par ID)
- **Timeout** : Utiliser `acquire(timeout=...)` pour √©viter les blocages infinis
- **Bloc try/finally** : Garantit que les verrous sont toujours lib√©r√©s

### 3.4 R√©sultat attendu

```
=== Test avec Deadlock Potentiel ===

Situation :
- Thread 1 : A -> B (acquiert A puis B)
- Thread 2 : B -> A (acquiert B puis A)
Risque : Deadlock si les deux threads s'ex√©cutent en m√™me temps

Thread Thread-1: Acquiert verrou A
Thread Thread-2: Acquiert verrou B
Thread Thread-1: Acquiert verrou B
Thread Thread-2: Acquiert verrou A

‚ö†Ô∏è  DEADLOCK D√âTECT√â ! Les threads sont bloqu√©s.
Solution : Utiliser un ordre constant pour les verrous.

√âtat final - Compte A: 1000, Compte B: 1000

==================================================

=== Test sans Deadlock (Ordre Constant) ===

Solution : Toujours acqu√©rir les verrous dans le m√™me ordre (A puis B)

Thread Thread-1: Acquiert verrou A
Thread Thread-2: Acquiert verrou A
Thread Thread-1: Acquiert verrou B
Thread Thread-1: Transfert de 100 de A vers B
Thread Thread-1: Verrous lib√©r√©s
Thread Thread-2: Acquiert verrou B
Thread Thread-2: Transfert de 50 de B vers A
Thread Thread-2: Verrous lib√©r√©s

‚úì Transferts termin√©s sans deadlock

√âtat final - Compte A: 950, Compte B: 1050
```

### 3.5 Analyse et am√©liorations possibles

**Analyse :**
- Le premier test montre le deadlock (threads bloqu√©s)
- Le deuxi√®me test montre la solution (ordre constant)
- Le timeout permet de d√©tecter et g√©rer les deadlocks

**Am√©liorations possibles :**
- Utiliser un contexte manager (`with verrou:`) pour une gestion automatique
- Impl√©menter un d√©tecteur de deadlock automatique
- Utiliser des transactions pour garantir la coh√©rence

---

## 4. Exercices

### Exercice 1 : D√©tecter une race condition

**Difficult√©** : ‚≠ê Facile  
**Temps estim√©** : 20-25 minutes  
**Objectif** : Identifier et corriger une race condition

**√ânonc√© :**
Cr√©ez un programme qui :
1. A une liste partag√©e `ma_liste = []`
2. Lance 3 threads qui ajoutent chacun 100 √©l√©ments √† la liste
3. Affiche la longueur finale de la liste
4. Identifie pourquoi la longueur n'est pas 300
5. Corrige le probl√®me avec un verrou

**Consignes :**
- Utilisez `threading.Thread` et `threading.Lock`
- Affichez clairement la diff√©rence entre avec et sans verrou

**Solution :**

```python
import threading

ma_liste = []
verrou = threading.Lock()

def ajouter_sans_verrou(nb_elements):
    """Ajoute des √©l√©ments sans protection."""
    global ma_liste
    for i in range(nb_elements):
        ma_liste.append(i)

def ajouter_avec_verrou(nb_elements):
    """Ajoute des √©l√©ments avec protection."""
    global ma_liste
    for i in range(nb_elements):
        verrou.acquire()
        try:
            ma_liste.append(i)
        finally:
            verrou.release()

# Test sans verrou
ma_liste = []
threads = []
for _ in range(3):
    t = threading.Thread(target=ajouter_sans_verrou, args=(100,))
    threads.append(t)
    t.start()

for t in threads:
    t.join()

print(f"Sans verrou : {len(ma_liste)} √©l√©ments (attendu: 300)")

# Test avec verrou
ma_liste = []
threads = []
for _ in range(3):
    t = threading.Thread(target=ajouter_avec_verrou, args=(100,))
    threads.append(t)
    t.start()

for t in threads:
    t.join()

print(f"Avec verrou : {len(ma_liste)} √©l√©ments (attendu: 300)")
```

**Explication de la solution :**
M√™me si `list.append()` semble atomique, dans un contexte multi-thread, il peut y avoir des probl√®mes. Le verrou garantit que l'op√©ration est vraiment atomique.

---

### Exercice 2 : √âviter un deadlock

**Difficult√©** : ‚≠ê‚≠ê Moyen  
**Temps estim√©** : 30-40 minutes  
**Objectif** : Impl√©menter une solution qui √©vite les deadlocks

**√ânonc√© :**
Cr√©ez un programme qui :
1. A 3 ressources avec 3 verrous (R1, R2, R3)
2. Cr√©e 3 threads qui ont besoin de 2 ressources chacun :
   - Thread 1 : R1 et R2
   - Thread 2 : R2 et R3
   - Thread 3 : R3 et R1
3. Impl√©mentez une fonction qui acquiert les verrous dans un ordre constant pour √©viter les deadlocks
4. Testez avec et sans l'ordre constant

**Consignes :**
- Utilisez un ordre bas√© sur l'ID de la ressource
- Affichez l'ordre d'acquisition des verrous
- Utilisez un timeout pour d√©tecter les deadlocks

**Solution :**

```python
import threading
import time

verrou_r1 = threading.Lock()
verrou_r2 = threading.Lock()
verrou_r3 = threading.Lock()

verrous = {
    'R1': verrou_r1,
    'R2': verrou_r2,
    'R3': verrou_r3
}

def utiliser_ressources(ressources, nom_thread, avec_ordre=True):
    """
    Utilise des ressources avec ou sans ordre constant.
    
    Args:
        ressources (list): Liste des noms de ressources
        nom_thread (str): Nom du thread
        avec_ordre (bool): Si True, trie les ressources par ordre
    """
    if avec_ordre:
        # SOLUTION : Trier les ressources pour avoir un ordre constant
        ressources = sorted(ressources)
        print(f"{nom_thread}: Ordre tri√© des ressources: {ressources}")
    
    verrous_acquises = []
    try:
        for ressource in ressources:
            verrou = verrous[ressource]
            print(f"{nom_thread}: Tentative d'acquisition de {ressource}")
            if verrou.acquire(timeout=2):
                verrous_acquises.append((ressource, verrou))
                print(f"{nom_thread}: {ressource} acquise")
                time.sleep(0.1)  # Simule un travail
            else:
                print(f"{nom_thread}: Timeout sur {ressource}")
                # Lib√©rer les verrous d√©j√† acquises
                for r, v in reversed(verrous_acquises):
                    v.release()
                    print(f"{nom_thread}: {r} lib√©r√©e")
                return False
        
        # Utiliser les ressources
        print(f"{nom_thread}: Utilisation des ressources {ressources}")
        time.sleep(0.5)
        print(f"{nom_thread}: Travail termin√©")
        return True
    finally:
        # Lib√©rer dans l'ordre inverse
        for ressource, verrou in reversed(verrous_acquises):
            verrou.release()
            print(f"{nom_thread}: {ressource} lib√©r√©e")

# Test avec ordre constant
print("=== Test avec ordre constant (pas de deadlock) ===\n")
thread1 = threading.Thread(target=utiliser_ressources, 
                           args=(['R1', 'R2'], 'Thread-1', True))
thread2 = threading.Thread(target=utiliser_ressources, 
                           args=(['R2', 'R3'], 'Thread-2', True))
thread3 = threading.Thread(target=utiliser_ressources, 
                           args=(['R3', 'R1'], 'Thread-3', True))

thread1.start()
thread2.start()
thread3.start()

thread1.join()
thread2.join()
thread3.join()

print("\n‚úì Tous les threads ont termin√©")
```

**Explication de la solution :**
En triant les ressources par nom, on garantit un ordre constant d'acquisition, √©vitant ainsi les deadlocks circulaires.

---

### Exercice 3 : Syst√®me de cache thread-safe

**Difficult√©** : ‚≠ê‚≠ê‚≠ê Avanc√©  
**Temps estim√©** : 45-60 minutes  
**Objectif** : Cr√©er un syst√®me de cache thread-safe avec gestion des race conditions

**√ânonc√© :**
Cr√©ez une classe `CacheThreadSafe` qui :
1. Stocke des paires cl√©-valeur
2. Permet d'ajouter, r√©cup√©rer et supprimer des √©l√©ments
3. Est thread-safe (plusieurs threads peuvent l'utiliser simultan√©ment)
4. Utilise un verrou pour prot√©ger les acc√®s
5. Teste avec plusieurs threads qui ajoutent/r√©cup√®rent des √©l√©ments

**Consignes :**
- Utilisez un dictionnaire pour stocker les donn√©es
- Prot√©gez toutes les op√©rations avec un verrou
- Testez avec des threads qui font des op√©rations concurrentes

**Solution :**

```python
import threading
import time
import random

class CacheThreadSafe:
    """Cache thread-safe pour stocker des paires cl√©-valeur."""
    
    def __init__(self):
        self._donnees = {}
        self._verrou = threading.RLock()  # RLock pour permettre les appels imbriqu√©s
        self._stats = {
            'lectures': 0,
            'ecritures': 0,
            'suppressions': 0
        }
    
    def ajouter(self, cle, valeur):
        """Ajoute ou met √† jour une entr√©e."""
        with self._verrou:
            self._donnees[cle] = valeur
            self._stats['ecritures'] += 1
            return True
    
    def recuperer(self, cle, valeur_par_defaut=None):
        """R√©cup√®re une valeur ou retourne la valeur par d√©faut."""
        with self._verrou:
            self._stats['lectures'] += 1
            return self._donnees.get(cle, valeur_par_defaut)
    
    def supprimer(self, cle):
        """Supprime une entr√©e."""
        with self._verrou:
            if cle in self._donnees:
                del self._donnees[cle]
                self._stats['suppressions'] += 1
                return True
            return False
    
    def taille(self):
        """Retourne le nombre d'√©l√©ments."""
        with self._verrou:
            return len(self._donnees)
    
    def obtenir_stats(self):
        """Retourne les statistiques d'utilisation."""
        with self._verrou:
            return self._stats.copy()
    
    def vider(self):
        """Vide le cache."""
        with self._verrou:
            self._donnees.clear()

def worker_ecriture(cache, nb_operations, nom):
    """Worker qui √©crit dans le cache."""
    for i in range(nb_operations):
        cle = f"cle_{nom}_{i}"
        valeur = f"valeur_{nom}_{i}"
        cache.ajouter(cle, valeur)
        time.sleep(random.uniform(0.001, 0.01))

def worker_lecture(cache, nb_operations, nom):
    """Worker qui lit dans le cache."""
    for i in range(nb_operations):
        cle = f"cle_thread_{i % 5}"  # Lit des cl√©s qui peuvent exister ou non
        cache.recuperer(cle)
        time.sleep(random.uniform(0.001, 0.01))

if __name__ == "__main__":
    cache = CacheThreadSafe()
    
    # Cr√©er des threads qui √©crivent
    threads_ecriture = []
    for i in range(3):
        t = threading.Thread(target=worker_ecriture, args=(cache, 10, i))
        threads_ecriture.append(t)
        t.start()
    
    # Cr√©er des threads qui lisent
    threads_lecture = []
    for i in range(2):
        t = threading.Thread(target=worker_lecture, args=(cache, 15, i))
        threads_lecture.append(t)
        t.start()
    
    # Attendre que tous se terminent
    for t in threads_ecriture + threads_lecture:
        t.join()
    
    print(f"Taille du cache : {cache.taille()}")
    print(f"Statistiques : {cache.obtenir_stats()}")
```

**Explication de la solution :**
Cette solution utilise un `RLock` (Reentrant Lock) qui permet au m√™me thread d'acqu√©rir le verrou plusieurs fois (utile si une m√©thode appelle une autre m√©thode de la m√™me classe). Le contexte manager `with` garantit la lib√©ration automatique du verrou.

---

## 5. R√©sum√©

### Concepts cl√©s
- ‚úÖ **Concurrence** : Gestion de plusieurs t√¢ches en alternance (apparente simultan√©it√©)
- ‚úÖ **Parall√©lisme** : Ex√©cution simultan√©e r√©elle sur plusieurs c≈ìurs
- ‚úÖ **Threads** : L√©gers, m√©moire partag√©e, affect√©s par le GIL
- ‚úÖ **Processus** : Isol√©s, m√©moire s√©par√©e, vrai parall√©lisme en Python
- ‚úÖ **Verrous** : M√©canisme de synchronisation pour prot√©ger les ressources
- ‚úÖ **Race condition** : R√©sultat d√©pendant de l'ordre d'ex√©cution non d√©terministe
- ‚úÖ **Deadlock** : Situation o√π des threads/processus s'attendent mutuellement

### Points importants √† retenir
1. La concurrence et le parall√©lisme sont diff√©rents : la concurrence est pour l'I/O, le parall√©lisme pour le CPU
2. Les threads partagent la m√©moire, les processus ont une m√©moire isol√©e
3. Toujours prot√©ger les ressources partag√©es avec des verrous
4. Utiliser un ordre constant pour acqu√©rir les verrous (√©vite les deadlocks)
5. Les race conditions sont difficiles √† d√©tecter mais faciles √† pr√©venir avec la synchronisation

### Pi√®ges √† √©viter
- ‚ö†Ô∏è **Oublier de lib√©rer un verrou** : Utilisez `with verrou:` ou `try/finally`
- ‚ö†Ô∏è **Acqu√©rir des verrous dans un ordre diff√©rent** : Toujours le m√™me ordre
- ‚ö†Ô∏è **Penser que les op√©rations simples sont atomiques** : Elles ne le sont pas toujours
- ‚ö†Ô∏è **Trop de verrous** : Peut r√©duire la parall√©lisation, utilisez-les seulement quand n√©cessaire

---

## 6. Pour aller plus loin

### Ressources suppl√©mentaires
- üìö "Operating System Concepts" - Chapitre sur la synchronisation
- üìö "The Art of Multiprocessor Programming" - Concepts avanc√©s
- üìö Documentation Python threading : https://docs.python.org/3/library/threading.html

### Concepts li√©s √† explorer
- **Lock-free programming** : Structures de donn√©es sans verrous
- **Atomic operations** : Op√©rations garanties atomiques par le processeur
- **Memory models** : Mod√®les de m√©moire pour comprendre la coh√©rence

### Projets sugg√©r√©s
- Impl√©menter un syst√®me de files d'attente thread-safe
- Cr√©er une biblioth√®que de structures de donn√©es thread-safe
- D√©velopper un syst√®me de logging thread-safe

---

## 7. Questions de r√©vision

1. Quelle est la diff√©rence fondamentale entre concurrence et parall√©lisme ?
2. Pourquoi les threads en Python ne permettent-ils pas le vrai parall√©lisme pour le calcul CPU ?
3. Qu'est-ce qu'une race condition et comment l'√©viter ?
4. Quelles sont les 4 conditions n√©cessaires pour qu'un deadlock se produise ?
5. Pourquoi est-il important d'acqu√©rir les verrous dans un ordre constant ?

---

*[Chapitre pr√©c√©dent : Chapitre 2 - Environnement] | [Chapitre suivant : Chapitre 4 - Threading en Python - Les bases]*
