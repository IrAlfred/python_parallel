# Chapitre 1 : Introduction √† la programmation parall√®le et distribu√©e

## Objectifs d'apprentissage
√Ä la fin de ce chapitre, vous serez capable de :
- Comprendre la diff√©rence entre programmation s√©quentielle, parall√®le et distribu√©e
- Identifier les situations o√π la programmation parall√®le est b√©n√©fique
- Comprendre les limitations de la programmation s√©quentielle
- Conna√Ætre les concepts de base de l'architecture des processeurs modernes
- Comprendre le GIL (Global Interpreter Lock) en Python et ses implications

---

## 1. Explication du principe

### 1.1 Programmation s√©quentielle vs parall√®le vs distribu√©e

**Programmation s√©quentielle** :
La programmation s√©quentielle est la m√©thode traditionnelle o√π les instructions sont ex√©cut√©es une apr√®s l'autre, dans l'ordre. C'est comme avoir un seul ouvrier qui fait toutes les t√¢ches une par une.

```python
# Exemple s√©quentiel
resultat1 = calcul_complexe_1()  # Prend 5 secondes
resultat2 = calcul_complexe_2()  # Prend 5 secondes
resultat3 = calcul_complexe_3()  # Prend 5 secondes
# Temps total : 15 secondes
```

**Programmation parall√®le** :
La programmation parall√®le consiste √† ex√©cuter plusieurs t√¢ches simultan√©ment sur plusieurs c≈ìurs d'un m√™me processeur ou sur plusieurs processeurs d'une m√™me machine. C'est comme avoir plusieurs ouvriers travaillant en m√™me temps sur la m√™me cha√Æne de production.

```python
# Exemple parall√®le (conceptuel)
# T√¢che 1, 2 et 3 s'ex√©cutent en m√™me temps
# Temps total : ~5 secondes (le temps de la plus longue t√¢che)
```

**Programmation distribu√©e** :
La programmation distribu√©e consiste √† ex√©cuter des t√¢ches sur plusieurs machines diff√©rentes connect√©es par un r√©seau. C'est comme avoir plusieurs usines dans diff√©rentes villes qui travaillent ensemble.

**Points cl√©s √† retenir :**
- **S√©quentiel** : Une t√¢che √† la fois, sur une seule machine
- **Parall√®le** : Plusieurs t√¢ches simultan√©es, sur une seule machine (plusieurs c≈ìurs)
- **Distribu√©** : Plusieurs t√¢ches simultan√©es, sur plusieurs machines

### 1.2 Pourquoi la programmation parall√®le ?

**Limitations physiques des processeurs** :
Depuis les ann√©es 2000, les fabricants de processeurs ont rencontr√© des limites physiques qui emp√™chent d'augmenter ind√©finiment la fr√©quence d'horloge (vitesse) d'un processeur. Au lieu de cr√©er des processeurs plus rapides, ils cr√©ent des processeurs avec plusieurs c≈ìurs.

**Avantages de la programmation parall√®le :**
1. **Performance** : R√©duction significative du temps d'ex√©cution pour les t√¢ches qui peuvent √™tre divis√©es
2. **Utilisation des ressources** : Meilleure utilisation des multiples c≈ìurs disponibles
3. **R√©activit√©** : Permet de maintenir une interface utilisateur r√©active pendant qu'un calcul s'ex√©cute en arri√®re-plan
4. **Scalabilit√©** : Possibilit√© d'ajouter plus de ressources pour traiter plus de donn√©es

**Quand utiliser la programmation parall√®le ?**
- Traitement de grandes quantit√©s de donn√©es
- Calculs ind√©pendants qui peuvent √™tre ex√©cut√©s simultan√©ment
- Op√©rations I/O (lecture/√©criture de fichiers, requ√™tes r√©seau) qui attendent souvent
- Simulations complexes avec de nombreux calculs ind√©pendants

**Quand NE PAS utiliser la programmation parall√®le ?**
- T√¢ches tr√®s simples et rapides (le co√ªt de cr√©ation des threads/processus d√©passe le gain)
- T√¢ches qui d√©pendent fortement les unes des autres (s√©quentielles par nature)
- Quand la synchronisation devient trop complexe

### 1.3 Architecture des processeurs modernes

**C≈ìurs de processeur** :
Un c≈ìur (core) est une unit√© de traitement ind√©pendante capable d'ex√©cuter des instructions. Les processeurs modernes ont g√©n√©ralement 4, 8, 16 c≈ìurs ou plus.

**Threads mat√©riels (Hyper-Threading)** :
Certains processeurs supportent plusieurs threads par c≈ìur (Intel Hyper-Threading, AMD SMT). Un processeur 4 c≈ìurs avec 2 threads par c≈ìur peut ex√©cuter 8 threads simultan√©ment.

**M√©moire** :
- **RAM** : M√©moire partag√©e accessible par tous les c≈ìurs
- **Cache** : M√©moire tr√®s rapide proche de chaque c≈ìur (L1, L2, L3)

**Points cl√©s √† retenir :**
- Plus de c≈ìurs = plus de t√¢ches peuvent s'ex√©cuter simultan√©ment
- La m√©moire est partag√©e entre tous les c≈ìurs
- Le cache permet d'acc√©der rapidement aux donn√©es fr√©quemment utilis√©es

### 1.4 Le GIL (Global Interpreter Lock) en Python

**Qu'est-ce que le GIL ?**
Le GIL est un m√©canisme dans l'impl√©mentation CPython de Python qui permet √† un seul thread d'ex√©cuter du code Python √† la fois. C'est un verrou global qui prot√®ge l'acc√®s aux objets Python.

**Pourquoi le GIL existe-t-il ?**
- Simplifie la gestion de la m√©moire (garbage collector)
- Prot√®ge les structures de donn√©es internes de Python
- Rend l'impl√©mentation de CPython plus simple et plus s√ªre

**Implications du GIL :**
- **Threading** : Les threads Python ne peuvent pas vraiment ex√©cuter du code Python en parall√®le sur plusieurs c≈ìurs
- **Multiprocessing** : Les processus Python peuvent s'ex√©cuter en parall√®le car chaque processus a son propre GIL
- **I/O** : Le GIL est lib√©r√© pendant les op√©rations I/O, donc le threading est efficace pour les op√©rations de fichiers/r√©seau

**Quand le GIL est-il lib√©r√© ?**
- Pendant les op√©rations I/O (lecture/√©criture fichiers, requ√™tes r√©seau)
- Dans certaines op√©rations C natives (NumPy, certaines fonctions de la biblioth√®que standard)
- Explicitement par certaines extensions C

**Points cl√©s √† retenir :**
- Le GIL limite le parall√©lisme r√©el avec les threads pour le calcul CPU
- Pour le calcul CPU intensif, utilisez `multiprocessing` plut√¥t que `threading`
- Pour les op√©rations I/O, `threading` fonctionne bien malgr√© le GIL

### 1.5 La loi d'Amdahl

**Qu'est-ce que la loi d'Amdahl ?**
La loi d'Amdahl est une formule qui permet de calculer l'acc√©l√©ration maximale th√©orique d'un programme lorsqu'on utilise la programmation parall√®le. Elle a √©t√© formul√©e par Gene Amdahl en 1967 et reste fondamentale pour comprendre les limites du parall√©lisme.

**Le principe fondamental :**
La loi d'Amdahl part d'une observation simple : tout programme comporte une partie qui peut √™tre parall√©lis√©e et une partie qui doit rester s√©quentielle. L'acc√©l√©ration maximale est limit√©e par cette partie s√©quentielle.

**La formule math√©matique :**

L'acc√©l√©ration th√©orique maximale $S$ avec $N$ processeurs est donn√©e par :

$$S(N) = \frac{1}{(1-P) + \frac{P}{N}}$$

O√π :
- $S(N)$ : Acc√©l√©ration avec $N$ processeurs
- $P$ : Proportion du programme qui peut √™tre parall√©lis√©e (entre 0 et 1)
- $1-P$ : Proportion du programme qui doit rester s√©quentielle
- $N$ : Nombre de processeurs

**Interpr√©tation :**
- Si $P = 1$ (100% parall√©lisable) : $S(N) = N$ (acc√©l√©ration lin√©aire parfaite)
- Si $P = 0$ (0% parall√©lisable) : $S(N) = 1$ (aucune acc√©l√©ration)
- Dans la r√©alit√© : $0 < P < 1$ (acc√©l√©ration limit√©e par la partie s√©quentielle)

**Acc√©l√©ration maximale th√©orique :**
Quand $N \to \infty$ (nombre infini de processeurs), l'acc√©l√©ration maximale est :

$$S_{max} = \frac{1}{1-P}$$

Cela signifie que m√™me avec un nombre infini de processeurs, on ne peut pas d√©passer cette limite impos√©e par la partie s√©quentielle.

**Exemples pratiques de calculs :**

**Exemple 1 : Programme 90% parall√©lisable**

Supposons un programme o√π 90% du code peut √™tre parall√©lis√© ($P = 0.9$) :

```python
def calculer_acceleration_amdahl(P, N):
    """
    Calcule l'acc√©l√©ration th√©orique selon la loi d'Amdahl.
    
    Args:
        P (float): Proportion parall√©lisable (entre 0 et 1)
        N (int): Nombre de processeurs
    
    Returns:
        float: Acc√©l√©ration th√©orique
    """
    return 1 / ((1 - P) + P / N)

# Programme 90% parall√©lisable
P = 0.9

# Calculer pour diff√©rents nombres de processeurs
print("Programme 90% parall√©lisable:")
print(f"{'Processeurs':<15} {'Acc√©l√©ration':<15} {'Efficacit√©':<15}")
print("-" * 45)

for N in [1, 2, 4, 8, 16, 32, 64, 128]:
    S = calculer_acceleration_amdahl(P, N)
    efficacite = (S / N) * 100
    print(f"{N:<15} {S:<15.2f} {efficacite:<15.1f}%")

# Acc√©l√©ration maximale th√©orique
S_max = 1 / (1 - P)
print(f"\nAcc√©l√©ration maximale th√©orique : {S_max:.2f}x")
```

**R√©sultat attendu :**
```
Programme 90% parall√©lisable:
Processeurs     Acc√©l√©ration    Efficacit√©     
---------------------------------------------
1               1.00            100.0%
2               1.82            90.9%
4               3.08            76.9%
8               4.71            58.8%
16              6.40            40.0%
32              7.80            24.4%
64              8.77            13.7%
128             9.30            7.3%

Acc√©l√©ration maximale th√©orique : 10.00x
```

**Analyse :**
- Avec 2 processeurs : acc√©l√©ration de 1.82x (pas 2x !)
- Avec 8 processeurs : acc√©l√©ration de 4.71x (pas 8x !)
- M√™me avec 128 processeurs, on atteint seulement 9.30x
- La limite maximale est 10x, peu importe le nombre de processeurs

**Exemple 2 : Comparaison de diff√©rents taux de parall√©lisation**

```python
import matplotlib.pyplot as plt  # Pour la visualisation (optionnel)

def analyser_impact_parallelisation():
    """Analyse l'impact du taux de parall√©lisation sur l'acc√©l√©ration."""
    
    # Diff√©rents taux de parall√©lisation
    taux_P = [0.50, 0.75, 0.90, 0.95, 0.99]
    nombre_processeurs = range(1, 65)
    
    print("=== Impact du taux de parall√©lisation ===\n")
    
    for P in taux_P:
        print(f"\nProgramme {int(P*100)}% parall√©lisable:")
        print(f"{'Processeurs':<15} {'Acc√©l√©ration':<15} {'% du maximum':<15}")
        print("-" * 45)
        
        S_max = 1 / (1 - P)
        
        for N in [1, 4, 8, 16, 32, 64]:
            S = calculer_acceleration_amdahl(P, N)
            pourcentage_max = (S / S_max) * 100
            print(f"{N:<15} {S:<15.2f} {pourcentage_max:<15.1f}%")
        
        print(f"Limite maximale : {S_max:.2f}x")

if __name__ == "__main__":
    analyser_impact_parallelisation()
```

**R√©sultat attendu :**
```
=== Impact du taux de parall√©lisation ===

Programme 50% parall√©lisable:
Processeurs     Acc√©l√©ration    % du maximum   
---------------------------------------------
1               1.00            50.0%
4               1.60            80.0%
8               1.78            88.9%
16              1.88            94.1%
32              1.94            96.9%
64              1.97            98.4%
Limite maximale : 2.00x

Programme 75% parall√©lisable:
Processeurs     Acc√©l√©ration    % du maximum   
---------------------------------------------
1               1.00            25.0%
4               2.29            57.1%
8               2.91            72.7%
16              3.37            84.2%
32              3.64            91.0%
64              3.80            95.0%
Limite maximale : 4.00x

Programme 90% parall√©lisable:
Processeurs     Acc√©l√©ration    % du maximum   
---------------------------------------------
1               1.00            10.0%
4               3.08            30.8%
8               4.71            47.1%
16              6.40            64.0%
32              7.80            78.0%
64              8.77            87.7%
Limite maximale : 10.00x

Programme 95% parall√©lisable:
Processeurs     Acc√©l√©ration    % du maximum   
---------------------------------------------
1               1.00            5.0%
4               3.48            17.4%
8               5.93            29.6%
16              9.14            45.7%
32              12.80           64.0%
64              15.53           77.6%
Limite maximale : 20.00x

Programme 99% parall√©lisable:
Processeurs     Acc√©l√©ration    % du maximum   
---------------------------------------------
1               1.00            1.0%
4               3.88            3.9%
8               7.48            7.5%
16              13.91           13.9%
32              24.43           24.4%
64              39.68           39.7%
Limite maximale : 100.00x
```

**Observations importantes :**
1. **Impact de la partie s√©quentielle** : M√™me 10% de code s√©quentiel ($P=0.9$) limite l'acc√©l√©ration √† 10x
2. **Rendements d√©croissants** : Plus on ajoute de processeurs, moins le gain est important
3. **Importance de la parall√©lisation** : Passer de 90% √† 95% de parall√©lisation double la limite th√©orique

**Exemple 3 : Calcul pratique pour un cas r√©el**

```python
def analyser_tache_reelle():
    """
    Analyse une t√¢che r√©elle avec ses temps mesur√©s.
    """
    print("=== Analyse d'une t√¢che r√©elle ===\n")
    
    # Mesures d'un programme r√©el (en secondes)
    temps_total_sequentiel = 100  # 100 secondes au total
    temps_partie_sequentielle = 15  # 15 secondes incompressibles
    temps_partie_parallelisable = 85  # 85 secondes parall√©lisables
    
    # Calculer P
    P = temps_partie_parallelisable / temps_total_sequentiel
    
    print(f"Temps total s√©quentiel : {temps_total_sequentiel}s")
    print(f"Partie s√©quentielle : {temps_partie_sequentielle}s ({(1-P)*100:.0f}%)")
    print(f"Partie parall√©lisable : {temps_partie_parallelisable}s ({P*100:.0f}%)")
    print(f"\nP = {P:.2f}\n")
    
    print(f"{'Processeurs':<15} {'Temps th√©orique':<20} {'Acc√©l√©ration':<15}")
    print("-" * 50)
    
    for N in [1, 2, 4, 8, 16]:
        S = calculer_acceleration_amdahl(P, N)
        temps_predit = temps_total_sequentiel / S
        print(f"{N:<15} {temps_predit:<20.2f}s {S:<15.2f}x")
    
    # Limite maximale
    S_max = 1 / (1 - P)
    temps_min = temps_total_sequentiel / S_max
    print(f"\n{'‚àû':<15} {temps_min:<20.2f}s {S_max:<15.2f}x (maximum)")
    print(f"\nTemps incompressible : {temps_partie_sequentielle}s")

if __name__ == "__main__":
    analyser_tache_reelle()
```

**R√©sultat attendu :**
```
=== Analyse d'une t√¢che r√©elle ===

Temps total s√©quentiel : 100s
Partie s√©quentielle : 15s (15%)
Partie parall√©lisable : 85s (85%)

P = 0.85

Processeurs     Temps th√©orique     Acc√©l√©ration   
--------------------------------------------------
1               100.00s             1.00x
2               57.50s              1.74x
4               36.25s              2.76x
8               25.63s              3.90x
16              20.31s              4.92x

‚àû               15.00s              6.67x (maximum)

Temps incompressible : 15s
```

**Interpr√©tation pratique :**
- M√™me avec un nombre infini de processeurs, on ne pourra jamais descendre sous 15 secondes
- Avec 4 processeurs, on √©conomise environ 64 secondes
- Avec 16 processeurs, on √©conomise 80 secondes, mais le gain diminue
- Au-del√† de 16 processeurs, le gain devient marginal pour cette t√¢che

**Limites de la loi d'Amdahl :**
1. **Overhead non pris en compte** : La loi suppose que la partie parall√©lisable s'acc√©l√®re parfaitement, sans co√ªt de communication ou synchronisation
2. **Taille fixe du probl√®me** : La loi suppose que la taille du probl√®me reste constante (voir la loi de Gustafson pour une approche alternative)
3. **Mod√®le simplifi√©** : En r√©alit√©, certaines parties peuvent avoir des comportements plus complexes

**Conseils pratiques bas√©s sur la loi d'Amdahl :**
1. **Identifier la partie s√©quentielle** : Avant de parall√©liser, mesurez quelle proportion de votre code peut vraiment √™tre parall√©lis√©e
2. **Calculer le nombre optimal de processeurs** : Inutile d'utiliser 64 processeurs si votre t√¢che est limit√©e √† 4x d'acc√©l√©ration
3. **Optimiser d'abord le s√©quentiel** : R√©duire la partie s√©quentielle a plus d'impact que d'ajouter des processeurs
4. **Mesurer les r√©sultats r√©els** : Comparez vos mesures avec les pr√©dictions d'Amdahl pour identifier les probl√®mes

**Points cl√©s √† retenir :**
- La loi d'Amdahl pr√©dit l'acc√©l√©ration maximale th√©orique en fonction de la proportion parall√©lisable
- M√™me une petite partie s√©quentielle limite drastiquement l'acc√©l√©ration maximale
- Il existe un point de rendement d√©croissant au-del√† duquel ajouter des processeurs n'apporte presque rien
- Optimiser la partie s√©quentielle est souvent plus efficace que d'ajouter des ressources

---

## 2. Exemples basiques

### 2.1 Exemple basique 1 : Comparaison s√©quentiel vs parall√®le

#### 2.1.1 Description

Nous allons cr√©er un exemple simple qui compare l'ex√©cution s√©quentielle et parall√®le d'une t√¢che de calcul. Cet exemple illustrera la diff√©rence de temps d'ex√©cution entre les deux approches.

**Ce que nous allons faire :**
- Cr√©er une fonction qui simule un calcul (somme de nombres)
- Ex√©cuter cette fonction plusieurs fois de mani√®re s√©quentielle
- Ex√©cuter cette fonction plusieurs fois de mani√®re parall√®le (avec multiprocessing)
- Comparer les temps d'ex√©cution

#### 2.1.2 Code

```python
import time
from multiprocessing import Process

def calcul_intensif(n):
    """
    Simule un calcul intensif en calculant la somme des nombres de 0 √† n.
    
    Args:
        n (int): Nombre jusqu'auquel calculer la somme
    
    Returns:
        int: La somme calcul√©e
    """
    somme = 0
    for i in range(n):
        somme += i
    return somme

def execution_sequentielle(taches):
    """
    Ex√©cute les t√¢ches de mani√®re s√©quentielle (une apr√®s l'autre).
    
    Args:
        taches (list): Liste des valeurs √† traiter
    
    Returns:
        float: Temps d'ex√©cution en secondes
    """
    debut = time.time()
    resultats = []
    for tache in taches:
        resultat = calcul_intensif(tache)
        resultats.append(resultat)
    fin = time.time()
    return fin - debut

def execution_parallele(taches):
    """
    Ex√©cute les t√¢ches de mani√®re parall√®le (simultan√©ment).
    
    Args:
        taches (list): Liste des valeurs √† traiter
    
    Returns:
        float: Temps d'ex√©cution en secondes
    """
    debut = time.time()
    processus = []
    
    # Cr√©er un processus pour chaque t√¢che
    for tache in taches:
        p = Process(target=calcul_intensif, args=(tache,))
        processus.append(p)
        p.start()
    
    # Attendre que tous les processus se terminent
    for p in processus:
        p.join()
    
    fin = time.time()
    return fin - debut

if __name__ == "__main__":
    # D√©finir les t√¢ches √† ex√©cuter
    # Chaque nombre repr√©sente la complexit√© d'un calcul
    taches = [10000000, 10000000, 10000000, 10000000]
    
    print("=== Comparaison S√©quentiel vs Parall√®le ===\n")
    
    # Ex√©cution s√©quentielle
    print("Ex√©cution s√©quentielle en cours...")
    temps_sequentiel = execution_sequentielle(taches)
    print(f"Temps s√©quentiel : {temps_sequentiel:.4f} secondes\n")
    
    # Ex√©cution parall√®le
    print("Ex√©cution parall√®le en cours...")
    temps_parallele = execution_parallele(taches)
    print(f"Temps parall√®le : {temps_parallele:.4f} secondes\n")
    
    # Comparaison
    acceleration = temps_sequentiel / temps_parallele
    print(f"Acc√©l√©ration : {acceleration:.2f}x")
    print(f"Gain de temps : {temps_sequentiel - temps_parallele:.4f} secondes")
```

#### 2.1.3 Explication ligne par ligne

**Lignes 1-2 : Importations**
- `time` : Pour mesurer le temps d'ex√©cution
- `Process` : Classe du module `multiprocessing` pour cr√©er des processus

**Lignes 4-15 : Fonction `calcul_intensif`**
- Simule un calcul qui prend du temps en faisant une boucle
- Cette fonction sera ex√©cut√©e plusieurs fois
- Plus `n` est grand, plus le calcul prend du temps

**Lignes 17-30 : Fonction `execution_sequentielle`**
- `debut = time.time()` : Enregistre le temps de d√©but
- La boucle `for` ex√©cute chaque t√¢che une apr√®s l'autre
- `fin = time.time()` : Enregistre le temps de fin
- Retourne la diff√©rence (temps total)

**Lignes 32-52 : Fonction `execution_parallele`**
- `debut = time.time()` : Enregistre le temps de d√©but
- `Process(target=calcul_intensif, args=(tache,))` : Cr√©e un nouveau processus qui ex√©cutera `calcul_intensif` avec `tache` comme argument
- `p.start()` : D√©marre le processus (il commence √† s'ex√©cuter)
- `p.join()` : Attend que le processus se termine avant de continuer
- Tous les processus s'ex√©cutent en parall√®le (simultan√©ment)

**Lignes 54-75 : Code principal**
- D√©finit 4 t√¢ches identiques
- Ex√©cute d'abord de mani√®re s√©quentielle, puis parall√®le
- Compare les r√©sultats

#### 2.1.4 R√©sultat attendu

```
=== Comparaison S√©quentiel vs Parall√®le ===

Ex√©cution s√©quentielle en cours...
Temps s√©quentiel : 2.3456 secondes

Ex√©cution parall√®le en cours...
Temps parall√®le : 0.6789 secondes

Acc√©l√©ration : 3.46x
Gain de temps : 1.6667 secondes
```

*Note : Les temps exacts varieront selon votre machine, mais vous devriez voir une acc√©l√©ration significative avec l'ex√©cution parall√®le.*

#### 2.1.5 Analyse du r√©sultat

Le r√©sultat montre que l'ex√©cution parall√®le est plus rapide que l'ex√©cution s√©quentielle. Sur une machine avec 4 c≈ìurs, on peut s'attendre √† une acc√©l√©ration proche de 4x (id√©alement). En pratique, l'acc√©l√©ration est souvent inf√©rieure √† cause de :
- Le temps de cr√©ation des processus
- Le temps de communication entre processus
- La charge du syst√®me

---

### 2.2 Exemple basique 2 : Utilisation de plusieurs c≈ìurs

#### 2.2.1 Description

Cet exemple montre comment v√©rifier le nombre de c≈ìurs disponibles sur votre machine et utiliser ce nombre pour optimiser le parall√©lisme.

**Ce que nous allons faire :**
- D√©tecter le nombre de c≈ìurs CPU disponibles
- Cr√©er un nombre optimal de processus
- Comparer les performances avec diff√©rents nombres de processus

#### 2.2.2 Code

```python
import time
import os
from multiprocessing import Process, cpu_count

def calcul_simple(n):
    """Effectue un calcul simple."""
    resultat = 0
    for i in range(n):
        resultat += i * i
    return resultat

def executer_avec_n_processus(nb_processus, taches):
    """Ex√©cute les t√¢ches avec un nombre sp√©cifi√© de processus."""
    debut = time.time()
    processus = []
    
    for tache in taches:
        p = Process(target=calcul_simple, args=(tache,))
        processus.append(p)
        p.start()
    
    for p in processus:
        p.join()
    
    fin = time.time()
    return fin - debut

if __name__ == "__main__":
    # D√©tecter le nombre de c≈ìurs
    nb_coeurs = cpu_count()
    print(f"Nombre de c≈ìurs CPU disponibles : {nb_coeurs}\n")
    
    taches = [5000000] * 8  # 8 t√¢ches identiques
    
    # Tester avec diff√©rents nombres de processus
    for nb_proc in [1, 2, 4, nb_coeurs, nb_coeurs * 2]:
        if nb_proc <= len(taches):
            temps = executer_avec_n_processus(nb_proc, taches[:nb_proc])
            print(f"{nb_proc} processus : {temps:.4f} secondes")
```

#### 2.2.3 Explication

- `cpu_count()` : Retourne le nombre de c≈ìurs CPU disponibles
- On teste diff√©rents nombres de processus pour voir l'impact
- G√©n√©ralement, le nombre optimal est proche du nombre de c≈ìurs

#### 2.2.4 R√©sultat attendu

```
Nombre de c≈ìurs CPU disponibles : 4

1 processus : 2.1234 secondes
2 processus : 1.2345 secondes
4 processus : 0.6789 secondes
4 processus : 0.7123 secondes
8 processus : 0.8901 secondes
```

---

### 2.3 Exemple basique 3 : Mesure de performance simple

#### 2.3.1 Description

Cet exemple montre comment mesurer et comparer les performances de mani√®re simple et reproductible.

**Ce que nous allons faire :**
- Cr√©er une fonction de calcul
- Mesurer le temps d'ex√©cution s√©quentiel
- Mesurer le temps d'ex√©cution parall√®le
- Afficher un rapport de performance

#### 2.3.2 Code

```python
import time
from multiprocessing import Process

def factorielle(n):
    """Calcule la factorielle de n."""
    if n <= 1:
        return 1
    resultat = 1
    for i in range(2, n + 1):
        resultat *= i
    return resultat

def test_sequentiel():
    """Test s√©quentiel."""
    debut = time.time()
    resultats = []
    for n in [1000, 2000, 3000, 4000]:
        resultats.append(factorielle(n))
    return time.time() - debut, resultats

def test_parallele():
    """Test parall√®le."""
    debut = time.time()
    processus = []
    resultats = [None] * 4
    
    def worker(index, valeur):
        resultats[index] = factorielle(valeur)
    
    valeurs = [1000, 2000, 3000, 4000]
    for i, val in enumerate(valeurs):
        p = Process(target=worker, args=(i, val))
        processus.append(p)
        p.start()
    
    for p in processus:
        p.join()
    
    return time.time() - debut, resultats

if __name__ == "__main__":
    print("=== Test de Performance ===\n")
    
    temps_seq, res_seq = test_sequentiel()
    print(f"Temps s√©quentiel : {temps_seq:.4f}s")
    
    temps_par, res_par = test_parallele()
    print(f"Temps parall√®le : {temps_par:.4f}s")
    
    acceleration = temps_seq / temps_par
    print(f"\nAcc√©l√©ration : {acceleration:.2f}x")
    print(f"Gain : {temps_seq - temps_par:.4f} secondes")
```

#### 2.3.3 Explication

- On mesure le temps pour chaque approche
- On calcule l'acc√©l√©ration obtenue
- On compare les r√©sultats pour v√©rifier qu'ils sont identiques

#### 2.3.4 R√©sultat attendu

```
=== Test de Performance ===

Temps s√©quentiel : 1.2345s
Temps parall√®le : 0.3456s

Acc√©l√©ration : 3.57x
Gain : 0.8889 secondes
```

---

## 3. Exemple avanc√©

### 3.1 Description

Nous allons cr√©er un exemple plus r√©aliste qui traite des fichiers en parall√®le. Cet exemple simule un sc√©nario o√π nous devons analyser plusieurs fichiers texte pour compter les mots. C'est un cas d'usage typique o√π la programmation parall√®le apporte un r√©el b√©n√©fice.

**Contexte :**
Imaginez que vous avez 10 fichiers texte volumineux et que vous voulez compter le nombre de mots dans chacun d'eux. Au lieu de les traiter un par un, nous allons les traiter en parall√®le.

**Objectifs :**
- Cr√©er des fichiers texte de test
- Traiter les fichiers de mani√®re s√©quentielle
- Traiter les fichiers de mani√®re parall√®le
- Comparer les performances et afficher les r√©sultats

### 3.2 Code

```python
import time
import os
from multiprocessing import Process, Queue
import random
import string

def generer_fichier_test(nom_fichier, nb_mots=100000):
    """
    G√©n√®re un fichier texte de test avec un nombre sp√©cifi√© de mots.
    
    Args:
        nom_fichier (str): Nom du fichier √† cr√©er
        nb_mots (int): Nombre de mots √† g√©n√©rer
    """
    mots = []
    for _ in range(nb_mots):
        # G√©n√®re un mot al√©atoire de 3 √† 10 caract√®res
        longueur = random.randint(3, 10)
        mot = ''.join(random.choices(string.ascii_lowercase, k=longueur))
        mots.append(mot)
    
    with open(nom_fichier, 'w', encoding='utf-8') as f:
        f.write(' '.join(mots))

def compter_mots(nom_fichier):
    """
    Compte le nombre de mots dans un fichier.
    
    Args:
        nom_fichier (str): Chemin vers le fichier
    
    Returns:
        tuple: (nom_fichier, nombre_de_mots)
    """
    try:
        with open(nom_fichier, 'r', encoding='utf-8') as f:
            contenu = f.read()
            mots = contenu.split()
            return (nom_fichier, len(mots))
    except Exception as e:
        return (nom_fichier, f"Erreur: {e}")

def traitement_sequentiel(fichiers):
    """
    Traite les fichiers de mani√®re s√©quentielle.
    
    Args:
        fichiers (list): Liste des chemins de fichiers
    
    Returns:
        dict: Dictionnaire {nom_fichier: nombre_mots}
    """
    debut = time.time()
    resultats = {}
    
    for fichier in fichiers:
        nom, nb_mots = compter_mots(fichier)
        resultats[nom] = nb_mots
    
    fin = time.time()
    return resultats, fin - debut

def worker_traitement(fichiers, queue_resultats):
    """
    Fonction ex√©cut√©e par chaque processus worker.
    Traite une liste de fichiers et met les r√©sultats dans la queue.
    
    Args:
        fichiers (list): Liste des fichiers √† traiter
        queue_resultats (Queue): Queue pour partager les r√©sultats
    """
    for fichier in fichiers:
        nom, nb_mots = compter_mots(fichier)
        queue_resultats.put((nom, nb_mots))

def traitement_parallele(fichiers, nb_processus=4):
    """
    Traite les fichiers de mani√®re parall√®le en utilisant plusieurs processus.
    
    Args:
        fichiers (list): Liste des chemins de fichiers
        nb_processus (int): Nombre de processus √† utiliser
    
    Returns:
        dict: Dictionnaire {nom_fichier: nombre_mots}
    """
    debut = time.time()
    
    # Diviser les fichiers entre les processus
    fichiers_par_processus = []
    for i in range(nb_processus):
        fichiers_par_processus.append([])
    
    # R√©partir les fichiers de mani√®re √©quitable
    for index, fichier in enumerate(fichiers):
        fichiers_par_processus[index % nb_processus].append(fichier)
    
    # Cr√©er une queue pour collecter les r√©sultats
    queue_resultats = Queue()
    
    # Cr√©er et d√©marrer les processus
    processus = []
    for fichiers_groupe in fichiers_par_processus:
        if fichiers_groupe:  # Ne cr√©er un processus que s'il y a des fichiers
            p = Process(target=worker_traitement, args=(fichiers_groupe, queue_resultats))
            processus.append(p)
            p.start()
    
    # Attendre que tous les processus se terminent
    for p in processus:
        p.join()
    
    # Collecter les r√©sultats de la queue
    resultats = {}
    while not queue_resultats.empty():
        nom, nb_mots = queue_resultats.get()
        resultats[nom] = nb_mots
    
    fin = time.time()
    return resultats, fin - debut

def nettoyer_fichiers_test(fichiers):
    """Supprime les fichiers de test cr√©√©s."""
    for fichier in fichiers:
        if os.path.exists(fichier):
            os.remove(fichier)

if __name__ == "__main__":
    # Configuration
    nb_fichiers = 10
    nb_mots_par_fichier = 50000
    nb_processus = 4
    
    print("=== Traitement de fichiers : S√©quentiel vs Parall√®le ===\n")
    
    # Cr√©er les fichiers de test
    print(f"Cr√©ation de {nb_fichiers} fichiers de test...")
    fichiers = [f"test_file_{i}.txt" for i in range(nb_fichiers)]
    for fichier in fichiers:
        generer_fichier_test(fichier, nb_mots_par_fichier)
    print("Fichiers cr√©√©s.\n")
    
    # Traitement s√©quentiel
    print("Traitement s√©quentiel en cours...")
    resultats_seq, temps_seq = traitement_sequentiel(fichiers)
    print(f"Temps s√©quentiel : {temps_seq:.4f} secondes")
    print(f"Total de mots trait√©s : {sum(resultats_seq.values())}\n")
    
    # Traitement parall√®le
    print(f"Traitement parall√®le en cours ({nb_processus} processus)...")
    resultats_par, temps_par = traitement_parallele(fichiers, nb_processus)
    print(f"Temps parall√®le : {temps_par:.4f} secondes")
    print(f"Total de mots trait√©s : {sum(resultats_par.values())}\n")
    
    # Comparaison
    acceleration = temps_seq / temps_par if temps_par > 0 else 0
    print("=== R√©sultats ===")
    print(f"Acc√©l√©ration : {acceleration:.2f}x")
    print(f"Gain de temps : {temps_seq - temps_par:.4f} secondes")
    print(f"Pourcentage d'am√©lioration : {((temps_seq - temps_par) / temps_seq * 100):.1f}%")
    
    # V√©rifier que les r√©sultats sont identiques
    if resultats_seq == resultats_par:
        print("\n‚úì Les r√©sultats sont identiques !")
    else:
        print("\n‚úó Attention : Les r√©sultats diff√®rent !")
    
    # Nettoyer
    print("\nNettoyage des fichiers de test...")
    nettoyer_fichiers_test(fichiers)
    print("Termin√©.")
```

### 3.3 Explication d√©taill√©e

**Architecture :**
L'exemple utilise une architecture "worker pool" o√π plusieurs processus (workers) traitent chacun une partie des fichiers. Les r√©sultats sont collect√©s via une Queue (file d'attente thread-safe).

**Fonctionnalit√©s :**

1. **G√©n√©ration de fichiers de test** (`generer_fichier_test`) :
   - Cr√©e des fichiers texte avec un nombre sp√©cifi√© de mots al√©atoires
   - Permet de tester sans avoir de vrais fichiers

2. **Comptage de mots** (`compter_mots`) :
   - Fonction simple qui lit un fichier et compte les mots
   - G√®re les erreurs de mani√®re gracieuse

3. **Traitement s√©quentiel** (`traitement_sequentiel`) :
   - Traite chaque fichier un par un
   - Simple et direct

4. **Traitement parall√®le** (`traitement_parallele`) :
   - Divise les fichiers entre plusieurs processus
   - Chaque processus traite sa portion de fichiers
   - Utilise une Queue pour collecter les r√©sultats de mani√®re thread-safe

**Points techniques importants :**

- **R√©partition des t√¢ches** : Les fichiers sont r√©partis de mani√®re √©quitable entre les processus (round-robin)
- **Queue pour r√©sultats** : La Queue permet de partager les r√©sultats entre processus de mani√®re s√ªre
- **Gestion des processus** : Tous les processus sont d√©marr√©s puis on attend qu'ils se terminent tous

### 3.4 R√©sultat attendu

```
=== Traitement de fichiers : S√©quentiel vs Parall√®le ===

Cr√©ation de 10 fichiers de test...
Fichiers cr√©√©s.

Traitement s√©quentiel en cours...
Temps s√©quentiel : 1.2345 secondes
Total de mots trait√©s : 500000

Traitement parall√®le en cours (4 processus)...
Temps parall√®le : 0.3456 secondes
Total de mots trait√©s : 500000

=== R√©sultats ===
Acc√©l√©ration : 3.57x
Gain de temps : 0.8889 secondes
Pourcentage d'am√©lioration : 72.0%

‚úì Les r√©sultats sont identiques !

Nettoyage des fichiers de test...
Termin√©.
```

### 3.5 Analyse et am√©liorations possibles

**Analyse :**
- L'ex√©cution parall√®le est significativement plus rapide
- Les r√©sultats sont identiques, ce qui confirme que le parall√©lisme n'a pas introduit d'erreurs
- L'acc√©l√©ration est proche du nombre de processus (4x id√©alement, ~3.5x en pratique)

**Am√©liorations possibles :**
- Utiliser `Pool` de `multiprocessing` pour simplifier le code
- Ajouter une barre de progression
- G√©rer les erreurs de mani√®re plus robuste
- Utiliser `concurrent.futures` pour une API plus moderne

---

## 4. Exercices

### Exercice 1 : Comparaison simple

**Difficult√©** : ‚≠ê Facile  
**Temps estim√©** : 15-20 minutes  
**Objectif** : Comprendre la diff√©rence entre s√©quentiel et parall√®le avec un exemple simple

**√ânonc√© :**
Cr√©ez un programme qui :
1. D√©finit une fonction `carre(n)` qui calcule et retourne n¬≤ (utilisez une boucle pour simuler un calcul)
2. Ex√©cute cette fonction 5 fois avec les valeurs [1000000, 2000000, 3000000, 4000000, 5000000] de mani√®re s√©quentielle
3. Ex√©cute la m√™me fonction avec les m√™mes valeurs de mani√®re parall√®le (utilisez `multiprocessing.Process`)
4. Affiche les temps d'ex√©cution et l'acc√©l√©ration obtenue

**Consignes :**
- Utilisez `time.time()` pour mesurer le temps
- Cr√©ez un processus pour chaque calcul dans la version parall√®le
- Affichez clairement les r√©sultats

**Solution :**

```python
import time
from multiprocessing import Process

def carre(n):
    """Calcule n¬≤ en simulant un calcul."""
    resultat = 0
    for i in range(n):
        resultat += i
    return resultat * 2 / n if n > 0 else 0  # Simulation d'un calcul

def sequentiel(valeurs):
    """Ex√©cution s√©quentielle."""
    debut = time.time()
    resultats = [carre(v) for v in valeurs]
    fin = time.time()
    return fin - debut, resultats

def parallele(valeurs):
    """Ex√©cution parall√®le."""
    debut = time.time()
    processus = []
    resultats = [None] * len(valeurs)
    
    def worker(index, valeur):
        resultats[index] = carre(valeur)
    
    for i, v in enumerate(valeurs):
        p = Process(target=worker, args=(i, v))
        processus.append(p)
        p.start()
    
    for p in processus:
        p.join()
    
    fin = time.time()
    return fin - debut, resultats

if __name__ == "__main__":
    valeurs = [1000000, 2000000, 3000000, 4000000, 5000000]
    
    print("Ex√©cution s√©quentielle...")
    temps_seq, _ = sequentiel(valeurs)
    print(f"Temps : {temps_seq:.4f}s\n")
    
    print("Ex√©cution parall√®le...")
    temps_par, _ = parallele(valeurs)
    print(f"Temps : {temps_par:.4f}s\n")
    
    print(f"Acc√©l√©ration : {temps_seq/temps_par:.2f}x")
```

**Explication de la solution :**
La solution cr√©e un processus pour chaque calcul. Chaque processus ex√©cute la fonction `carre` ind√©pendamment. Les r√©sultats sont stock√©s dans une liste partag√©e (bien que dans cet exemple simple, nous ne les utilisons pas vraiment).

---

### Exercice 2 : Analyse de performance

**Difficult√©** : ‚≠ê‚≠ê Moyen  
**Temps estim√©** : 30-40 minutes  
**Objectif** : Analyser l'impact du nombre de processus sur les performances

**√ânonc√© :**
Modifiez l'exemple avanc√© du chapitre pour tester diff√©rentes configurations :
1. Testez avec 1, 2, 4, et 8 processus
2. Pour chaque configuration, mesurez le temps d'ex√©cution
3. Cr√©ez un graphique (ou un tableau) montrant le temps en fonction du nombre de processus
4. Identifiez le nombre optimal de processus pour votre machine

**Consignes :**
- Utilisez le m√™me ensemble de fichiers pour tous les tests
- R√©p√©tez chaque test plusieurs fois et prenez la moyenne
- Affichez les r√©sultats sous forme de tableau

**Solution :**

```python
import time
from multiprocessing import Process, Queue
import statistics

# [Reprendre les fonctions de l'exemple avanc√© : generer_fichier_test, 
#  compter_mots, worker_traitement, traitement_parallele]

def test_configurations(fichiers, configurations, nb_repetitions=3):
    """
    Teste diff√©rentes configurations de processus.
    
    Args:
        fichiers (list): Liste des fichiers √† traiter
        configurations (list): Liste du nombre de processus √† tester
        nb_repetitions (int): Nombre de r√©p√©titions par configuration
    
    Returns:
        dict: {nb_processus: temps_moyen}
    """
    resultats = {}
    
    for nb_proc in configurations:
        temps_liste = []
        print(f"Test avec {nb_proc} processus...")
        
        for _ in range(nb_repetitions):
            _, temps = traitement_parallele(fichiers, nb_proc)
            temps_liste.append(temps)
        
        temps_moyen = statistics.mean(temps_liste)
        resultats[nb_proc] = temps_moyen
        print(f"  Temps moyen : {temps_moyen:.4f}s\n")
    
    return resultats

if __name__ == "__main__":
    # Cr√©er les fichiers de test
    nb_fichiers = 8
    fichiers = [f"test_file_{i}.txt" for i in range(nb_fichiers)]
    for fichier in fichiers:
        generer_fichier_test(fichier, 30000)
    
    # Tester diff√©rentes configurations
    configurations = [1, 2, 4, 8]
    resultats = test_configurations(fichiers, configurations)
    
    # Afficher les r√©sultats
    print("=== R√©sultats ===")
    print("Processus | Temps (s) | Acc√©l√©ration")
    print("-" * 40)
    temps_ref = resultats[1]
    for nb_proc, temps in sorted(resultats.items()):
        accel = temps_ref / temps
        print(f"    {nb_proc}    |  {temps:.4f}  |  {accel:.2f}x")
    
    # Trouver l'optimal
    optimal = min(resultats.items(), key=lambda x: x[1])
    print(f"\nConfiguration optimale : {optimal[0]} processus ({optimal[1]:.4f}s)")
    
    # Nettoyer
    for fichier in fichiers:
        if os.path.exists(fichier):
            os.remove(fichier)
```

**Explication de la solution :**
Cette solution teste syst√©matiquement diff√©rentes configurations et identifie celle qui offre les meilleures performances. On remarque g√©n√©ralement que l'optimal correspond au nombre de c≈ìurs disponibles, mais peut √™tre limit√© par d'autres facteurs (I/O, m√©moire).

---

### Exercice 3 : Application pratique

**Difficult√©** : ‚≠ê‚≠ê‚≠ê Avanc√©  
**Temps estim√©** : 45-60 minutes  
**Objectif** : Cr√©er une application compl√®te utilisant la programmation parall√®le

**√ânonc√© :**
Cr√©ez un programme qui :
1. G√©n√®re 20 fichiers CSV avec des donn√©es al√©atoires (colonnes : id, nom, age, salaire)
2. Calcule des statistiques pour chaque fichier (moyenne d'√¢ge, salaire moyen, nombre d'enregistrements)
3. Traite les fichiers en parall√®le
4. G√©n√®re un rapport final avec toutes les statistiques
5. Compare les temps d'ex√©cution s√©quentiel vs parall√®le

**Consignes :**
- Utilisez le module `csv` pour cr√©er et lire les fichiers
- Chaque fichier doit avoir environ 1000 lignes
- Les statistiques doivent inclure : nombre de lignes, √¢ge moyen, salaire moyen, salaire maximum
- Affichez un rapport format√© √† la fin

**Solution :**

```python
import csv
import random
import time
from multiprocessing import Process, Queue
import os

def generer_csv(nom_fichier, nb_lignes=1000):
    """G√©n√®re un fichier CSV avec des donn√©es al√©atoires."""
    with open(nom_fichier, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['id', 'nom', 'age', 'salaire'])
        
        for i in range(nb_lignes):
            writer.writerow([
                i + 1,
                f"Personne_{random.randint(1, 1000)}",
                random.randint(22, 65),
                random.randint(30000, 100000)
            ])

def analyser_csv(nom_fichier):
    """Analyse un fichier CSV et retourne des statistiques."""
    try:
        with open(nom_fichier, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            ages = []
            salaires = []
            nb_lignes = 0
            
            for row in reader:
                ages.append(int(row['age']))
                salaires.append(int(row['salaire']))
                nb_lignes += 1
            
            if nb_lignes == 0:
                return (nom_fichier, None)
            
            stats = {
                'nb_lignes': nb_lignes,
                'age_moyen': sum(ages) / len(ages),
                'salaire_moyen': sum(salaires) / len(salaires),
                'salaire_max': max(salaires)
            }
            return (nom_fichier, stats)
    except Exception as e:
        return (nom_fichier, f"Erreur: {e}")

def worker_analyse(fichiers, queue):
    """Worker qui analyse des fichiers."""
    for fichier in fichiers:
        resultat = analyser_csv(fichier)
        queue.put(resultat)

def traitement_parallele_complet(fichiers, nb_processus=4):
    """Traite les fichiers en parall√®le."""
    debut = time.time()
    
    # R√©partir les fichiers
    fichiers_par_proc = [[] for _ in range(nb_processus)]
    for i, fichier in enumerate(fichiers):
        fichiers_par_proc[i % nb_processus].append(fichier)
    
    queue = Queue()
    processus = []
    
    for fichiers_groupe in fichiers_par_proc:
        if fichiers_groupe:
            p = Process(target=worker_analyse, args=(fichiers_groupe, queue))
            processus.append(p)
            p.start()
    
    for p in processus:
        p.join()
    
    # Collecter les r√©sultats
    resultats = {}
    while not queue.empty():
        nom, stats = queue.get()
        resultats[nom] = stats
    
    fin = time.time()
    return resultats, fin - debut

if __name__ == "__main__":
    # G√©n√©rer les fichiers
    nb_fichiers = 20
    fichiers = [f"data_{i}.csv" for i in range(nb_fichiers)]
    
    print("G√©n√©ration des fichiers CSV...")
    for fichier in fichiers:
        generer_csv(fichier, 1000)
    print("Termin√©.\n")
    
    # Traitement s√©quentiel
    print("Traitement s√©quentiel...")
    debut_seq = time.time()
    resultats_seq = {}
    for fichier in fichiers:
        nom, stats = analyser_csv(fichier)
        resultats_seq[nom] = stats
    temps_seq = time.time() - debut_seq
    print(f"Temps : {temps_seq:.4f}s\n")
    
    # Traitement parall√®le
    print("Traitement parall√®le (4 processus)...")
    resultats_par, temps_par = traitement_parallele_complet(fichiers, 4)
    print(f"Temps : {temps_par:.4f}s\n")
    
    # Rapport
    print("=== RAPPORT FINAL ===\n")
    print(f"{'Fichier':<20} {'Lignes':<10} {'√Çge moy.':<12} {'Salaire moy.':<15} {'Salaire max':<12}")
    print("-" * 75)
    
    for fichier in sorted(fichiers):
        stats = resultats_par.get(fichier, {})
        if stats:
            print(f"{fichier:<20} {stats['nb_lignes']:<10} {stats['age_moyen']:<12.1f} "
                  f"{stats['salaire_moyen']:<15.0f} {stats['salaire_max']:<12}")
    
    print(f"\nAcc√©l√©ration : {temps_seq/temps_par:.2f}x")
    
    # Nettoyer
    for fichier in fichiers:
        if os.path.exists(fichier):
            os.remove(fichier)
```

**Explication de la solution :**
Cette solution combine plusieurs concepts : g√©n√©ration de donn√©es, traitement parall√®le, et g√©n√©ration de rapports. Elle montre un cas d'usage r√©el o√π la programmation parall√®le apporte un b√©n√©fice significatif.

---

## 5. R√©sum√©

### Concepts cl√©s
- ‚úÖ **Programmation s√©quentielle** : Ex√©cution une t√¢che √† la fois, dans l'ordre
- ‚úÖ **Programmation parall√®le** : Ex√©cution simultan√©e de plusieurs t√¢ches sur plusieurs c≈ìurs d'une m√™me machine
- ‚úÖ **Programmation distribu√©e** : Ex√©cution simultan√©e de plusieurs t√¢ches sur plusieurs machines
- ‚úÖ **GIL (Global Interpreter Lock)** : M√©canisme Python qui limite le parall√©lisme r√©el avec les threads pour le calcul CPU

### Points importants √† retenir
1. La programmation parall√®le permet d'utiliser efficacement les multiples c≈ìurs des processeurs modernes
2. Le GIL limite l'efficacit√© du threading pour les calculs CPU, mais pas pour les op√©rations I/O
3. Pour les calculs CPU intensifs, `multiprocessing` est g√©n√©ralement pr√©f√©rable √† `threading`
4. L'acc√©l√©ration obtenue d√©pend de nombreux facteurs : nombre de c≈ìurs, nature des t√¢ches, overhead de communication

### Pi√®ges √† √©viter
- ‚ö†Ô∏è **Parall√©liser des t√¢ches trop simples** : Le co√ªt de cr√©ation des processus peut d√©passer le gain
- ‚ö†Ô∏è **Oublier le GIL** : Ne pas comprendre que les threads Python ne parall√©lisent pas vraiment le code Python pour le calcul CPU
- ‚ö†Ô∏è **Trop de processus** : Cr√©er plus de processus que de c≈ìurs disponibles peut d√©grader les performances

---

## 6. Pour aller plus loin

### Ressources suppl√©mentaires
- üìö Documentation Python - Threading : https://docs.python.org/3/library/threading.html
- üìö Documentation Python - Multiprocessing : https://docs.python.org/3/library/multiprocessing.html
- üìö Article sur le GIL : https://wiki.python.org/moin/GlobalInterpreterLock
- üìö "High Performance Python" par Micha Gorelick et Ian Ozsvald

### Concepts li√©s √† explorer
- **Concurrence vs Parall√©lisme** : Diff√©rence subtile mais importante
- **Loi de Gustafson** : Alternative √† la loi d'Amdahl pour les probl√®mes √† taille variable (scaled speedup)
- **Efficacit√© parall√®le** : Rapport entre l'acc√©l√©ration obtenue et le nombre de processeurs utilis√©s
- **Overhead de parall√©lisation** : Co√ªts cach√©s de la cr√©ation et synchronisation des processus/threads

### Projets sugg√©r√©s
- Cr√©er un outil de traitement d'images en parall√®le
- D√©velopper un scraper web parall√®le
- Impl√©menter un syst√®me de calcul distribu√© simple

---

## 7. Questions de r√©vision

1. Quelle est la principale diff√©rence entre programmation parall√®le et distribu√©e ?
2. Pourquoi le GIL existe-t-il en Python et quelles sont ses implications ?
3. Dans quels cas la programmation parall√®le apporte-t-elle un r√©el b√©n√©fice ?
4. Pourquoi l'acc√©l√©ration obtenue est-elle souvent inf√©rieure au nombre de processus utilis√©s ?
5. Quelle approche (threading ou multiprocessing) est pr√©f√©rable pour un calcul CPU intensif en Python ?
6. Selon la loi d'Amdahl, quelle est l'acc√©l√©ration maximale th√©orique d'un programme qui est parall√©lisable √† 80% ?
7. Pourquoi m√™me une petite partie s√©quentielle (ex: 5%) limite-t-elle significativement l'acc√©l√©ration maximale ?
8. Comment la loi d'Amdahl peut-elle vous aider √† d√©cider du nombre optimal de processeurs √† utiliser ?

---

*[Chapitre suivant : Chapitre 2 - Environnement de d√©veloppement et outils]*
