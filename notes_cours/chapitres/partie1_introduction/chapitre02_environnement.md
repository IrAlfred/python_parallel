# Chapitre 2 : Environnement de d√©veloppement et outils

## Objectifs d'apprentissage
√Ä la fin de ce chapitre, vous serez capable de :
- Configurer un environnement Python pour la programmation parall√®le
- Utiliser les modules `time` et `timeit` pour mesurer les performances
- Profiler du code avec `cProfile` pour identifier les goulots d'√©tranglement
- Visualiser les performances de votre code
- Utiliser des outils modernes pour le d√©veloppement parall√®le

---

## 1. Explication du principe

### 1.1 Configuration de l'environnement Python

**Version de Python recommand√©e :**
Pour la programmation parall√®le, il est recommand√© d'utiliser Python 3.8 ou sup√©rieur. Les versions r√©centes incluent des am√©liorations importantes pour `multiprocessing` et `asyncio`.

**V√©rifier votre version :**
```bash
python3 --version
# ou
python --version
```

**Environnement virtuel :**
Il est fortement recommand√© d'utiliser un environnement virtuel pour isoler les d√©pendances de votre projet :

```bash
# Cr√©er un environnement virtuel
python3 -m venv venv

# Activer l'environnement
# Sur Linux/Mac :
source venv/bin/activate
# Sur Windows :
venv\Scripts\activate
```

**Points cl√©s √† retenir :**
- Utilisez toujours un environnement virtuel pour vos projets
- Python 3.8+ est recommand√© pour les meilleures performances
- Gardez vos packages √† jour

### 1.2 Mesure du temps d'ex√©cution

**Pourquoi mesurer ?**
Avant d'optimiser, il faut mesurer. La mesure du temps d'ex√©cution permet de :
- Identifier les parties lentes du code
- Valider que les optimisations apportent r√©ellement un b√©n√©fice
- Comparer diff√©rentes approches

**Module `time` :**
Le module `time` fournit `time.time()` qui retourne le temps en secondes depuis le 1er janvier 1970 (epoch Unix).

**Module `timeit` :**
Le module `timeit` est sp√©cialement con√ßu pour mesurer le temps d'ex√©cution de petits morceaux de code. Il r√©p√®te l'ex√©cution plusieurs fois pour obtenir une mesure plus pr√©cise.

**Points cl√©s √† retenir :**
- `time.time()` : Mesure simple mais peut √™tre affect√©e par d'autres processus
- `timeit` : Plus pr√©cis car r√©p√®te l'ex√©cution et calcule une moyenne
- Toujours mesurer plusieurs fois et prendre une moyenne

### 1.3 Profiling avec cProfile

**Qu'est-ce que le profiling ?**
Le profiling consiste √† analyser le temps pass√© dans chaque fonction de votre programme. Cela permet d'identifier les "goulots d'√©tranglement" (bottlenecks) - les parties du code qui prennent le plus de temps.

**cProfile :**
`cProfile` est un profiler int√©gr√© √† Python qui enregistre :
- Le nombre d'appels √† chaque fonction
- Le temps total pass√© dans chaque fonction
- Le temps cumul√© (incluant les appels aux sous-fonctions)

**Sortie du profiler :**
Le profiler g√©n√®re des statistiques d√©taill√©es montrant quelles fonctions consomment le plus de temps, permettant de cibler les optimisations.

**Points cl√©s √† retenir :**
- Le profiling r√©v√®le o√π le code passe vraiment son temps
- Ne devinez pas, mesurez !
- 20% du code prend souvent 80% du temps (principe de Pareto)

### 1.4 Visualisation des performances

**Pourquoi visualiser ?**
Les graphiques et tableaux permettent de :
- Comparer facilement diff√©rentes approches
- Identifier les tendances
- Pr√©senter les r√©sultats de mani√®re claire

**Outils de visualisation :**
- `matplotlib` : Biblioth√®que standard pour cr√©er des graphiques
- Tableaux format√©s : Pour afficher des donn√©es structur√©es
- Graphiques de performance : Temps vs nombre de processus, etc.

**Points cl√©s √† retenir :**
- Une bonne visualisation vaut mieux qu'un long discours
- Les graphiques aident √† comprendre les relations entre variables
- Gardez les visualisations simples et claires

---

## 2. Exemples basiques

### 2.1 Exemple basique 1 : Comparaison time.time() vs timeit

#### 2.1.1 Description

Nous allons cr√©er un exemple simple qui montre comment mesurer le temps d'ex√©cution d'une fonction de diff√©rentes mani√®res. Cet exemple illustrera l'utilisation de `time.time()` et `timeit`.

**Ce que nous allons faire :**
- Cr√©er une fonction qui fait un calcul
- Mesurer son temps d'ex√©cution avec `time.time()`
- Mesurer son temps d'ex√©cution avec `timeit`
- Comparer les deux approches

#### 2.1.2 Code

```python
import time
import timeit

def calcul_simple(n):
    """
    Effectue un calcul simple : somme des carr√©s de 0 √† n.
    
    Args:
        n (int): Nombre jusqu'auquel calculer
    
    Returns:
        int: La somme des carr√©s
    """
    somme = 0
    for i in range(n):
        somme += i * i
    return somme

def mesure_avec_time(fonction, *args, nb_iterations=1):
    """
    Mesure le temps d'ex√©cution avec time.time().
    
    Args:
        fonction: La fonction √† mesurer
        *args: Arguments √† passer √† la fonction
        nb_iterations (int): Nombre de fois √† ex√©cuter
    
    Returns:
        float: Temps moyen en secondes
    """
    temps_total = 0
    
    for _ in range(nb_iterations):
        debut = time.time()
        fonction(*args)
        fin = time.time()
        temps_total += (fin - debut)
    
    return temps_total / nb_iterations

def mesure_avec_timeit(fonction, *args, nb_iterations=1000):
    """
    Mesure le temps d'ex√©cution avec timeit.
    
    Args:
        fonction: La fonction √† mesurer
        *args: Arguments √† passer √† la fonction
        nb_iterations (int): Nombre de r√©p√©titions
    
    Returns:
        float: Temps moyen en secondes
    """
    # Cr√©er une cha√Æne de code √† ex√©cuter
    code = f"{fonction.__name__}({', '.join(map(str, args))})"
    
    # Cr√©er un setup pour importer la fonction
    setup = f"from __main__ import {fonction.__name__}"
    
    # Mesurer avec timeit
    temps = timeit.timeit(code, setup=setup, number=nb_iterations)
    
    return temps / nb_iterations

if __name__ == "__main__":
    valeur_test = 10000
    
    print("=== Comparaison des m√©thodes de mesure ===\n")
    
    # Mesure avec time.time()
    print("1. Mesure avec time.time() (1 it√©ration) :")
    temps_time = mesure_avec_time(calcul_simple, valeur_test, nb_iterations=1)
    print(f"   Temps : {temps_time:.6f} secondes\n")
    
    # Mesure avec time.time() (moyenne sur 10 it√©rations)
    print("2. Mesure avec time.time() (moyenne sur 10 it√©rations) :")
    temps_time_moyen = mesure_avec_time(calcul_simple, valeur_test, nb_iterations=10)
    print(f"   Temps moyen : {temps_time_moyen:.6f} secondes\n")
    
    # Mesure avec timeit
    print("3. Mesure avec timeit (1000 it√©rations) :")
    temps_timeit = mesure_avec_timeit(calcul_simple, valeur_test, nb_iterations=1000)
    print(f"   Temps moyen : {temps_timeit:.6f} secondes\n")
    
    # Comparaison
    print("=== Comparaison ===")
    print(f"time.time() (1x)     : {temps_time:.6f}s")
    print(f"time.time() (10x)    : {temps_time_moyen:.6f}s")
    print(f"timeit (1000x)       : {temps_timeit:.6f}s")
    print(f"\nDiff√©rence relative : {abs(temps_time_moyen - temps_timeit) / temps_timeit * 100:.2f}%")
```

#### 2.1.3 Explication ligne par ligne

**Lignes 1-2 : Importations**
- `time` : Pour `time.time()`
- `timeit` : Pour des mesures plus pr√©cises

**Lignes 4-16 : Fonction `calcul_simple`**
- Fonction de test qui fait un calcul simple mais qui prend du temps
- Utilis√©e comme exemple pour les mesures

**Lignes 18-35 : Fonction `mesure_avec_time`**
- Utilise `time.time()` pour mesurer le temps
- Peut r√©p√©ter la mesure plusieurs fois et calculer une moyenne
- Plus simple mais moins pr√©cis que `timeit`

**Lignes 37-52 : Fonction `mesure_avec_timeit`**
- Utilise `timeit.timeit()` qui est sp√©cialement con√ßu pour mesurer
- R√©p√®te l'ex√©cution automatiquement
- Plus pr√©cis car g√®re mieux les variations du syst√®me

**Lignes 54-79 : Code principal**
- Compare les trois m√©thodes de mesure
- Montre que `timeit` est g√©n√©ralement plus fiable pour des mesures pr√©cises

#### 2.1.4 R√©sultat attendu

```
=== Comparaison des m√©thodes de mesure ===

1. Mesure avec time.time() (1 it√©ration) :
   Temps : 0.002345 secondes

2. Mesure avec time.time() (moyenne sur 10 it√©rations) :
   Temps moyen : 0.002301 secondes

3. Mesure avec timeit (1000 it√©rations) :
   Temps moyen : 0.002298 secondes

=== Comparaison ===
time.time() (1x)     : 0.002345s
time.time() (10x)    : 0.002301s
timeit (1000x)       : 0.002298s

Diff√©rence relative : 0.13%
```

#### 2.1.5 Analyse du r√©sultat

Les r√©sultats montrent que :
- Une seule mesure peut √™tre impr√©cise (variations du syst√®me)
- La moyenne sur plusieurs mesures est plus fiable
- `timeit` avec beaucoup de r√©p√©titions donne la mesure la plus pr√©cise

---

### 2.2 Exemple basique 2 : Mesure de plusieurs fonctions

#### 2.2.1 Description

Cet exemple montre comment comparer les performances de plusieurs fonctions diff√©rentes en utilisant timeit.

**Ce que nous allons faire :**
- Cr√©er plusieurs fonctions qui font le m√™me calcul diff√©remment
- Mesurer chaque fonction avec timeit
- Comparer leurs performances

#### 2.2.2 Code

```python
import timeit

def somme_boucle(n):
    """Somme avec une boucle for."""
    resultat = 0
    for i in range(n):
        resultat += i
    return resultat

def somme_builtin(n):
    """Somme avec la fonction built-in sum()."""
    return sum(range(n))

def somme_comprehension(n):
    """Somme avec une list comprehension."""
    return sum([i for i in range(n)])

if __name__ == "__main__":
    n = 10000
    nb_iterations = 1000
    
    print("=== Comparaison de performances ===\n")
    
    fonctions = [
        ("Boucle for", somme_boucle),
        ("Built-in sum()", somme_builtin),
        ("List comprehension", somme_comprehension)
    ]
    
    resultats = []
    for nom, fonction in fonctions:
        temps = timeit.timeit(lambda: fonction(n), number=nb_iterations)
        resultats.append((nom, temps))
        print(f"{nom:20s}: {temps*1000:.4f} ms")
    
    # Trouver la plus rapide
    plus_rapide = min(resultats, key=lambda x: x[1])
    print(f"\nPlus rapide: {plus_rapide[0]}")
```

#### 2.2.3 Explication

- On compare trois impl√©mentations diff√©rentes
- timeit permet d'obtenir des mesures pr√©cises
- On peut identifier la meilleure approche

---

### 2.3 Exemple basique 3 : Mesure avec contexte

#### 2.3.1 Description

Cet exemple montre comment mesurer le temps d'ex√©cution d'un bloc de code avec un contexte manager.

**Ce que nous allons faire :**
- Cr√©er un contexte manager pour mesurer le temps
- Utiliser ce contexte pour mesurer diff√©rentes op√©rations
- Afficher les r√©sultats

#### 2.3.2 Code

```python
import time
from contextlib import contextmanager

@contextmanager
def chronometre(nom):
    """Contexte manager pour mesurer le temps."""
    debut = time.time()
    print(f"[{nom}] D√©but")
    try:
        yield
    finally:
        fin = time.time()
        duree = fin - debut
        print(f"[{nom}] Fin - Dur√©e: {duree:.4f}s")

def operation_1():
    """Premi√®re op√©ration."""
    time.sleep(0.5)
    return "R√©sultat 1"

def operation_2():
    """Deuxi√®me op√©ration."""
    time.sleep(0.3)
    return "R√©sultat 2"

if __name__ == "__main__":
    with chronometre("Op√©ration 1"):
        resultat1 = operation_1()
    
    with chronometre("Op√©ration 2"):
        resultat2 = operation_2()
    
    print(f"\nR√©sultats: {resultat1}, {resultat2}")
```

#### 2.3.3 Explication

- Le contexte manager simplifie la mesure
- Utile pour mesurer des blocs de code
- Facile √† r√©utiliser

---

## 3. Exemple avanc√©

### 3.1 Description

Nous allons cr√©er un exemple complet qui utilise le profiler `cProfile` pour analyser un programme et identifier les parties lentes. Nous visualiserons √©galement les r√©sultats avec des graphiques.

**Contexte :**
Imaginez que vous avez un programme qui traite des donn√©es et vous voulez savoir quelle partie prend le plus de temps pour pouvoir l'optimiser.

**Objectifs :**
- Cr√©er un programme avec plusieurs fonctions
- Profiler le programme avec `cProfile`
- Analyser les r√©sultats du profiler
- Visualiser les performances avec des graphiques

### 3.2 Code

```python
import time
import cProfile
import pstats
import io
from functools import wraps

def fonction_rapide(n):
    """Fonction qui s'ex√©cute rapidement."""
    return sum(range(n))

def fonction_lente(n):
    """Fonction qui prend plus de temps."""
    resultat = 0
    for i in range(n):
        for j in range(100):
            resultat += i * j
    return resultat

def fonction_tres_lente(n):
    """Fonction qui prend beaucoup de temps."""
    resultat = 0
    for i in range(n):
        for j in range(n):
            for k in range(10):
                resultat += i * j * k
    return resultat

def traitement_donnees():
    """Fonction principale qui traite des donn√©es."""
    print("Traitement des donn√©es en cours...")
    
    # Appels √† diff√©rentes fonctions
    resultat1 = fonction_rapide(1000)
    resultat2 = fonction_lente(500)
    resultat3 = fonction_tres_lente(100)
    resultat4 = fonction_rapide(2000)
    resultat5 = fonction_lente(300)
    
    return resultat1 + resultat2 + resultat3 + resultat4 + resultat5

def profiler_fonction(fonction, *args, **kwargs):
    """
    Profile une fonction et affiche les r√©sultats.
    
    Args:
        fonction: La fonction √† profiler
        *args: Arguments positionnels
        **kwargs: Arguments nomm√©s
    """
    # Cr√©er un profiler
    profiler = cProfile.Profile()
    
    # D√©marrer le profilage
    profiler.enable()
    
    # Ex√©cuter la fonction
    resultat = fonction(*args, **kwargs)
    
    # Arr√™ter le profilage
    profiler.disable()
    
    # Cr√©er un objet StringIO pour capturer la sortie
    s = io.StringIO()
    
    # Cr√©er un objet Stats pour analyser les r√©sultats
    stats = pstats.Stats(profiler, stream=s)
    
    # Trier par temps cumul√©
    stats.sort_stats('cumulative')
    
    # Afficher les 10 fonctions les plus lentes
    stats.print_stats(10)
    
    # R√©cup√©rer la sortie
    sortie = s.getvalue()
    
    return resultat, sortie

def analyser_profiler(sortie_profiler):
    """
    Analyse la sortie du profiler et extrait des informations utiles.
    
    Args:
        sortie_profiler (str): Sortie textuelle du profiler
    """
    lignes = sortie_profiler.split('\n')
    
    print("\n=== Analyse du Profiler ===\n")
    
    # Chercher les lignes avec les statistiques
    fonctions_trouvees = []
    for ligne in lignes:
        if 'function_rapide' in ligne or 'function_lente' in ligne or 'function_tres_lente' in ligne:
            fonctions_trouvees.append(ligne.strip())
    
    if fonctions_trouvees:
        print("Fonctions identifi√©es dans le profiler :")
        for func in fonctions_trouvees[:5]:  # Afficher les 5 premi√®res
            print(f"  - {func}")
    else:
        print("Aucune fonction sp√©cifique trouv√©e (analyse manuelle requise)")

if __name__ == "__main__":
    print("=== Profiling d'un programme ===\n")
    
    # Profiler la fonction principale
    resultat, sortie = profiler_fonction(traitement_donnees)
    
    print("R√©sultat du traitement :", resultat)
    print("\n=== Rapport du Profiler ===\n")
    print(sortie)
    
    # Analyser les r√©sultats
    analyser_profiler(sortie)
    
    # Exemple d'utilisation avec timeit pour comparer
    print("\n=== Comparaison avec timeit ===\n")
    
    import timeit
    
    temps_rapide = timeit.timeit(lambda: fonction_rapide(1000), number=1000)
    temps_lente = timeit.timeit(lambda: fonction_lente(500), number=10)
    temps_tres_lente = timeit.timeit(lambda: fonction_tres_lente(100), number=1)
    
    print(f"fonction_rapide(1000)  : {temps_rapide*1000:.4f} ms (moyenne sur 1000 ex√©cutions)")
    print(f"fonction_lente(500)    : {temps_lente*1000:.4f} ms (moyenne sur 10 ex√©cutions)")
    print(f"fonction_tres_lente(100): {temps_tres_lente*1000:.4f} ms (1 ex√©cution)")
    
    print("\n=== Recommandations ===")
    print("D'apr√®s le profiler, concentrez-vous sur l'optimisation de :")
    print("1. fonction_tres_lente (prend le plus de temps)")
    print("2. fonction_lente (prend du temps mod√©r√©)")
    print("3. fonction_rapide (d√©j√† optimale, ne pas toucher)")
```

### 3.3 Explication d√©taill√©e

**Architecture :**
Le programme cr√©e plusieurs fonctions avec des complexit√©s diff√©rentes, puis utilise `cProfile` pour identifier laquelle prend le plus de temps.

**Fonctionnalit√©s :**

1. **Fonctions de test** :
   - `fonction_rapide` : Simple et rapide
   - `fonction_lente` : Boucles imbriqu√©es, plus lente
   - `fonction_tres_lente` : Triple boucle, tr√®s lente

2. **Profiling** (`profiler_fonction`) :
   - Cr√©e un objet `cProfile.Profile()`
   - Active le profilage avant l'ex√©cution
   - D√©sactive apr√®s l'ex√©cution
   - Utilise `pstats.Stats` pour analyser les r√©sultats

3. **Analyse des r√©sultats** :
   - Extrait les informations importantes
   - Identifie les fonctions les plus lentes
   - Donne des recommandations

**Points techniques importants :**

- **cProfile.Profile()** : Cr√©e un profiler qui enregistre toutes les informations
- **pstats.Stats** : Permet d'analyser et de trier les r√©sultats du profiler
- **sort_stats('cumulative')** : Trie par temps cumul√© (incluant les sous-fonctions)
- Le profiler montre le nombre d'appels, le temps total, et le temps par appel

### 3.4 R√©sultat attendu

```
=== Profiling d'un programme ===

Traitement des donn√©es en cours...
R√©sultat du traitement : 124750000

=== Rapport du Profiler ===

         1234567 function calls in 2.345 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    2.345    2.345 chapitre02.py:25(traitement_donnees)
        1    1.890    1.890    1.890    1.890 chapitre02.py:17(fonction_tres_lente)
        1    0.450    0.450    0.450    0.450 chapitre02.py:11(fonction_lente)
        2    0.005    0.003    0.005    0.003 chapitre02.py:5(fonction_rapide)
      ...

=== Analyse du Profiler ===

Fonctions identifi√©es dans le profiler :
  - fonction_tres_lente: 1.890s
  - fonction_lente: 0.450s
  - fonction_rapide: 0.005s

=== Comparaison avec timeit ===

fonction_rapide(1000)  : 0.1234 ms (moyenne sur 1000 ex√©cutions)
fonction_lente(500)    : 45.6789 ms (moyenne sur 10 ex√©cutions)
fonction_tres_lente(100): 1890.1234 ms (1 ex√©cution)

=== Recommandations ===
D'apr√®s le profiler, concentrez-vous sur l'optimisation de :
1. fonction_tres_lente (prend le plus de temps)
2. fonction_lente (prend du temps mod√©r√©)
3. fonction_rapide (d√©j√† optimale, ne pas toucher)
```

### 3.5 Analyse et am√©liorations possibles

**Analyse :**
Le profiler montre clairement que `fonction_tres_lente` est le goulot d'√©tranglement principal (80% du temps). C'est l√† qu'il faut concentrer les efforts d'optimisation.

**Am√©liorations possibles :**
- Utiliser `snakeviz` pour visualiser le profiler de mani√®re interactive
- Exporter les r√©sultats en JSON pour analyse approfondie
- Int√©grer le profiling dans les tests unitaires
- Utiliser `line_profiler` pour profiler ligne par ligne

---

## 4. Exercices

### Exercice 1 : Mesure de performance

**Difficult√©** : ‚≠ê Facile  
**Temps estim√©** : 15-20 minutes  
**Objectif** : Ma√Ætriser l'utilisation de `time` et `timeit`

**√ânonc√© :**
Cr√©ez un programme qui :
1. D√©finit trois fonctions : `fonction_a`, `fonction_b`, `fonction_c` qui font des calculs diff√©rents
2. Mesure le temps d'ex√©cution de chaque fonction avec `timeit` (100 ex√©cutions)
3. Affiche un tableau comparatif des performances
4. Identifie la fonction la plus rapide et la plus lente

**Consignes :**
- Utilisez `timeit.timeit()` pour toutes les mesures
- Affichez les r√©sultats en millisecondes
- Formatez le tableau de mani√®re lisible

**Solution :**

```python
import timeit

def fonction_a(n):
    """Calcule la somme de 0 √† n."""
    return sum(range(n))

def fonction_b(n):
    """Calcule la somme des carr√©s."""
    return sum(i*i for i in range(n))

def fonction_c(n):
    """Calcule avec une boucle explicite."""
    resultat = 0
    for i in range(n):
        resultat += i * i
    return resultat

if __name__ == "__main__":
    n = 10000
    nb_iterations = 100
    
    print("=== Comparaison de performances ===\n")
    
    # Mesurer chaque fonction
    temps_a = timeit.timeit(lambda: fonction_a(n), number=nb_iterations)
    temps_b = timeit.timeit(lambda: fonction_b(n), number=nb_iterations)
    temps_c = timeit.timeit(lambda: fonction_c(n), number=nb_iterations)
    
    # Convertir en millisecondes
    temps_a_ms = temps_a / nb_iterations * 1000
    temps_b_ms = temps_b / nb_iterations * 1000
    temps_c_ms = temps_c / nb_iterations * 1000
    
    # Afficher le tableau
    print(f"{'Fonction':<15} {'Temps (ms)':<15} {'Rapport':<15}")
    print("-" * 45)
    print(f"{'fonction_a':<15} {temps_a_ms:<15.4f} {'1.00x':<15}")
    
    rapport_b = temps_b_ms / temps_a_ms
    rapport_c = temps_c_ms / temps_a_ms
    print(f"{'fonction_b':<15} {temps_b_ms:<15.4f} {rapport_b:.2f}x")
    print(f"{'fonction_c':<15} {temps_c_ms:<15.4f} {rapport_c:.2f}x")
    
    # Identifier la plus rapide et la plus lente
    resultats = {
        'fonction_a': temps_a_ms,
        'fonction_b': temps_b_ms,
        'fonction_c': temps_c_ms
    }
    
    plus_rapide = min(resultats.items(), key=lambda x: x[1])
    plus_lente = max(resultats.items(), key=lambda x: x[1])
    
    print(f"\nPlus rapide : {plus_rapide[0]} ({plus_rapide[1]:.4f} ms)")
    print(f"Plus lente  : {plus_lente[0]} ({plus_lente[1]:.4f} ms)")
```

**Explication de la solution :**
Cette solution compare trois impl√©mentations diff√©rentes du m√™me calcul. `timeit` permet d'obtenir des mesures pr√©cises et reproductibles.

---

### Exercice 2 : Profiling d'une application

**Difficult√©** : ‚≠ê‚≠ê Moyen  
**Temps estim√©** : 30-40 minutes  
**Objectif** : Utiliser cProfile pour identifier les goulots d'√©tranglement

**√ânonc√© :**
Cr√©ez un programme qui :
1. Simule le traitement d'une liste de clients (calcul de factures)
2. Utilise `cProfile` pour profiler l'application
3. Analyse les r√©sultats et identifie les 3 fonctions les plus lentes
4. Propose des optimisations bas√©es sur les r√©sultats

**Consignes :**
- Cr√©ez au moins 5 fonctions diff√©rentes
- Utilisez `pstats` pour analyser les r√©sultats
- Affichez un rapport format√©

**Solution :**

```python
import cProfile
import pstats
import io

class Client:
    def __init__(self, nom, achats):
        self.nom = nom
        self.achats = achats

def calculer_tva(montant):
    """Calcule la TVA (20%)."""
    time.sleep(0.001)  # Simule un calcul
    return montant * 0.20

def calculer_remise(montant_total):
    """Calcule une remise bas√©e sur le montant."""
    time.sleep(0.002)  # Simule un calcul plus long
    if montant_total > 1000:
        return montant_total * 0.10
    elif montant_total > 500:
        return montant_total * 0.05
    return 0

def traiter_achat(achat):
    """Traite un achat individuel."""
    time.sleep(0.0005)
    tva = calculer_tva(achat)
    return achat + tva

def calculer_facture(client):
    """Calcule la facture totale pour un client."""
    total = 0
    for achat in client.achats:
        total += traiter_achat(achat)
    
    remise = calculer_remise(total)
    return total - remise

def traiter_clients(clients):
    """Traite une liste de clients."""
    factures = []
    for client in clients:
        facture = calculer_facture(client)
        factures.append((client.nom, facture))
    return factures

if __name__ == "__main__":
    import time
    
    # Cr√©er des clients de test
    clients = [
        Client("Alice", [100, 200, 300]),
        Client("Bob", [500, 600]),
        Client("Charlie", [50, 75, 100, 150])
    ] * 100  # Multiplier pour avoir plus de donn√©es
    
    # Profiler
    profiler = cProfile.Profile()
    profiler.enable()
    
    resultats = traiter_clients(clients)
    
    profiler.disable()
    
    # Analyser
    s = io.StringIO()
    stats = pstats.Stats(profiler, stream=s)
    stats.sort_stats('cumulative')
    stats.print_stats(10)
    
    print(s.getvalue())
    
    # Identifier les 3 plus lentes
    stats.sort_stats('tottime')
    print("\n=== Top 3 des fonctions les plus lentes (temps total) ===\n")
    stats.print_stats(3)
```

**Explication de la solution :**
Cette solution montre comment utiliser `cProfile` sur une application plus complexe et comment analyser les r√©sultats pour identifier les optimisations prioritaires.

---

### Exercice 3 : Outil de benchmarking

**Difficult√©** : ‚≠ê‚≠ê‚≠ê Avanc√©  
**Temps estim√©** : 45-60 minutes  
**Objectif** : Cr√©er un outil r√©utilisable pour mesurer les performances

**√ânonc√© :**
Cr√©ez une classe `Benchmark` qui :
1. Permet de mesurer facilement plusieurs fonctions
2. R√©p√®te les mesures plusieurs fois et calcule des statistiques (moyenne, min, max, √©cart-type)
3. Affiche les r√©sultats sous forme de tableau comparatif
4. Peut exporter les r√©sultats en CSV

**Consignes :**
- Utilisez `timeit` pour les mesures
- Calculez les statistiques avec le module `statistics`
- Cr√©ez une m√©thode pour exporter en CSV

**Solution :**

```python
import timeit
import statistics
import csv
from typing import Callable, List, Dict, Any

class Benchmark:
    """Classe pour mesurer et comparer les performances de fonctions."""
    
    def __init__(self, nb_iterations=1000):
        """
        Initialise le benchmark.
        
        Args:
            nb_iterations (int): Nombre d'it√©rations par mesure
        """
        self.nb_iterations = nb_iterations
        self.resultats = {}
    
    def mesurer(self, nom: str, fonction: Callable, *args, **kwargs):
        """
        Mesure une fonction.
        
        Args:
            nom (str): Nom de la fonction (pour l'identifier)
            fonction (Callable): Fonction √† mesurer
            *args, **kwargs: Arguments √† passer √† la fonction
        """
        # Cr√©er le code √† ex√©cuter
        if args or kwargs:
            code = f"fonction({', '.join(map(str, args))})"
        else:
            code = "fonction()"
        
        # Mesurer plusieurs fois pour avoir des statistiques
        temps_liste = []
        for _ in range(10):  # 10 mesures
            temps = timeit.timeit(code, 
                                globals={'fonction': lambda: fonction(*args, **kwargs)},
                                number=self.nb_iterations)
            temps_liste.append(temps / self.nb_iterations)
        
        # Calculer les statistiques
        self.resultats[nom] = {
            'moyenne': statistics.mean(temps_liste),
            'min': min(temps_liste),
            'max': max(temps_liste),
            'ecart_type': statistics.stdev(temps_liste) if len(temps_liste) > 1 else 0
        }
    
    def afficher_resultats(self):
        """Affiche les r√©sultats sous forme de tableau."""
        if not self.resultats:
            print("Aucun r√©sultat √† afficher.")
            return
        
        print("\n=== R√©sultats du Benchmark ===\n")
        print(f"{'Fonction':<20} {'Moyenne (s)':<15} {'Min (s)':<15} {'Max (s)':<15} {'√âcart-type':<15}")
        print("-" * 80)
        
        # Trier par temps moyen
        resultats_tries = sorted(self.resultats.items(), 
                               key=lambda x: x[1]['moyenne'])
        
        temps_reference = resultats_tries[0][1]['moyenne']
        
        for nom, stats in resultats_tries:
            rapport = stats['moyenne'] / temps_reference
            print(f"{nom:<20} {stats['moyenne']:<15.6f} {stats['min']:<15.6f} "
                  f"{stats['max']:<15.6f} {stats['ecart_type']:<15.6f} "
                  f"({rapport:.2f}x)")
    
    def exporter_csv(self, nom_fichier='benchmark_results.csv'):
        """Exporte les r√©sultats en CSV."""
        with open(nom_fichier, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Fonction', 'Moyenne (s)', 'Min (s)', 'Max (s)', '√âcart-type'])
            
            for nom, stats in sorted(self.resultats.items(), 
                                   key=lambda x: x[1]['moyenne']):
                writer.writerow([
                    nom,
                    stats['moyenne'],
                    stats['min'],
                    stats['max'],
                    stats['ecart_type']
                ])
        
        print(f"\nR√©sultats export√©s dans {nom_fichier}")

# Exemple d'utilisation
if __name__ == "__main__":
    def fonction_rapide(n):
        return sum(range(n))
    
    def fonction_moyenne(n):
        return sum(i*i for i in range(n))
    
    def fonction_lente(n):
        resultat = 0
        for i in range(n):
            for j in range(10):
                resultat += i * j
        return resultat
    
    benchmark = Benchmark(nb_iterations=100)
    
    n = 1000
    benchmark.mesurer("Fonction rapide", fonction_rapide, n)
    benchmark.mesurer("Fonction moyenne", fonction_moyenne, n)
    benchmark.mesurer("Fonction lente", fonction_lente, n)
    
    benchmark.afficher_resultats()
    benchmark.exporter_csv()
```

**Explication de la solution :**
Cette solution cr√©e un outil r√©utilisable pour le benchmarking. La classe `Benchmark` encapsule toute la logique de mesure et d'analyse, rendant le code plus propre et r√©utilisable.

---

## 5. R√©sum√©

### Concepts cl√©s
- ‚úÖ **time.time()** : Mesure simple du temps d'ex√©cution
- ‚úÖ **timeit** : Module sp√©cialis√© pour des mesures pr√©cises et reproductibles
- ‚úÖ **cProfile** : Profiler int√©gr√© √† Python pour identifier les goulots d'√©tranglement
- ‚úÖ **pstats** : Module pour analyser et trier les r√©sultats du profiler

### Points importants √† retenir
1. Toujours mesurer avant d'optimiser - ne devinez pas o√π sont les probl√®mes
2. Utilisez `timeit` pour des mesures pr√©cises de petites fonctions
3. Utilisez `cProfile` pour analyser des programmes complets
4. R√©p√©tez les mesures plusieurs fois pour obtenir des statistiques fiables
5. Visualisez les r√©sultats pour mieux les comprendre

### Pi√®ges √† √©viter
- ‚ö†Ô∏è **Mesurer une seule fois** : Les variations du syst√®me peuvent fausser les r√©sultats
- ‚ö†Ô∏è **Optimiser sans profiler** : Vous pourriez optimiser la mauvaise partie du code
- ‚ö†Ô∏è **Ignorer l'overhead** : Le temps de cr√©ation des processus/threads peut masquer les gains

---

## 6. Pour aller plus loin

### Ressources suppl√©mentaires
- üìö Documentation timeit : https://docs.python.org/3/library/timeit.html
- üìö Documentation cProfile : https://docs.python.org/3/library/profile.html
- üìö SnakeViz : Outil de visualisation interactive pour cProfile
- üìö line_profiler : Profiler ligne par ligne pour identifier les lignes lentes

### Concepts li√©s √† explorer
- **Memory profiling** : Analyser l'utilisation de la m√©moire
- **Visualisation avec matplotlib** : Cr√©er des graphiques de performance
- **Int√©gration continue** : Int√©grer le benchmarking dans les tests

### Projets sugg√©r√©s
- Cr√©er un framework de benchmarking r√©utilisable
- D√©velopper un outil de visualisation des profils de performance
- Int√©grer le profiling dans un pipeline CI/CD

---

## 7. Questions de r√©vision

1. Quelle est la diff√©rence entre `time.time()` et `timeit.timeit()` ?
2. Pourquoi est-il important de r√©p√©ter les mesures plusieurs fois ?
3. Qu'est-ce qu'un "goulot d'√©tranglement" et comment le profiler l'identifie-t-il ?
4. Dans quels cas utiliseriez-vous `cProfile` plut√¥t que `timeit` ?
5. Comment interpr√©ter les colonnes `tottime` et `cumtime` dans le rapport de cProfile ?

---

*[Chapitre pr√©c√©dent : Chapitre 1 - Introduction] | [Chapitre suivant : Chapitre 3 - Concepts fondamentaux]*
